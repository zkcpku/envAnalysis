{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from autocomplete import extract_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"code_example.py\",'r') as f:\n",
    "    content = f.read()\n",
    "    # rst = extract(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._knn(k, x, PQ, self.root)\n",
      "        for n in nearest:\n",
      "            n.distance = self.metric(x, n.key)\n",
      "        return nearest\n",
      "\n",
      "    def _knn(self, k, x, PQ, root):\n",
      "        dist = self.metric\n",
      "        dist_to_ball = dist(x, root.centroid) - root.radius\n",
      "        dist_to_farthest_neighbor = dist(x, PQ.peek()[\"key\"]) if len(PQ) > 0 else np.inf\n",
      "\n",
      "        if dist_to_ball >= dist_to_farthest_neighbor and len(PQ) == k:\n",
      "            return PQ\n",
      "        if root.is_leaf:\n",
      "            targets = [None] * len(root.data) if root.targets is None else root.targets\n",
      "            for point, target in zip(root.data, targets):\n",
      "                dist_to_x = dist(x, point)\n",
      "                if len(PQ) == k and dist_to_x < dist_to_farthest_neighbor:\n",
      "                    PQ.push(key=point, val=target, priority=dist_to_x)\n",
      "                else:\n",
      "                    PQ.push(key=point, val=target, priority=dist_to_x)\n",
      "        else:\n",
      "            l_closest = dist(x, root.left.centroid) < dist(x, root.right.centroid)\n",
      "            PQ = self._knn(k, x, PQ, root.left if l_closest else root.right)\n",
      "            PQ = self._knn(k, x, PQ, root.right if l_closest else root.left)\n",
      "        return PQ\n",
      "\n",
      "\n",
      "#######################################################################\n",
      "#                         Multinomial Sampler                         #\n",
      "#######################################################################\n",
      "\n",
      "\n",
      "class DiscreteSampler:\n",
      "    def __init__(self, probs, log=False, with_replacement=True):\n",
      "        \"\"\"\n",
      "        Sample from an arbitrary multinomial PMF over the first `N` nonnegative\n",
      "        integers using Vose's algorithm for the alias method.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Vose's algorithm takes `O(n)` time to initialize, requires `O(n)` memory,\n",
      "        and generates samples in constant time.\n",
      "\n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Walker, A. J. (1977) \"An efficient method for generating discrete\n",
      "           random variables with general distributions\". *ACM Transactions on\n",
      "           Mathematical Software, 3(3)*, 253-256.\n",
      "\n",
      "        .. [2] Vose, M. D. (1991) \"A linear algorithm for generating random numbers\n",
      "           with a given distribution\". *IEEE Trans. Softw. Eng., 9*, 972-974.\n",
      "\n",
      "        .. [3] Schwarz, K (2011) \"Darts, dice, and coins: sampling from a discrete\n",
      "           distribution\". http://www.keithschwarz.com/darts-dice-coins/\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        probs : :py:class:`ndarray <numpy.ndarray>` of length `(N,)`\n",
      "            A list of probabilities of the `N` outcomes in the sample space.\n",
      "            `probs[i]` returns the probability of outcome `i`.\n",
      "        log : bool\n",
      "            Whether the probabilities in `probs` are in logspace. Default is\n",
      "            False.\n",
      "        with_replacement : bool\n",
      "            Whether to generate samples with or without replacement. Default is\n",
      "            True.\n",
      "        \"\"\"\n",
      "        if not isinstance(probs, np.ndarray):\n",
      "            probs = np.array(probs)\n",
      "\n",
      "        self.log = log\n",
      "        self.N = len(probs)\n",
      "        self.probs = probs\n",
      "        self.with_replacement = with_replacement\n",
      "\n",
      "        alias = np.zeros(self.N)\n",
      "        prob = np.zeros(self.N)\n",
      "        scaled_probs = self.probs + np.log(self.N) if log else self.probs * self.N\n",
      "\n",
      "        selector = scaled_probs < 0 if log else scaled_probs < 1\n",
      "        small, large = np.where(selector)[0].tolist(), np.where(~selector)[0].tolist()\n",
      "\n",
      "        while len(small) and len(large):\n",
      "            l, g = small.pop(), large.pop()\n",
      "\n",
      "            alias[l] = g\n",
      "            prob[l] = scaled_probs[l]\n",
      "\n",
      "            if log:\n",
      "                pg = np.log(np.exp(scaled_probs[g]) + np.exp(scaled_probs[l]) - 1)\n",
      "            else:\n",
      "                pg = scaled_probs[g] + scaled_probs[l] - 1\n",
      "\n",
      "            scaled_probs[g] = pg\n",
      "            to_small = pg < 0 if log else pg < 1\n",
      "            if to_small:\n",
      "                small.append(g)\n",
      "            else:\n",
      "                large.append(g)\n",
      "\n",
      "        while len(large):\n",
      "            prob[large.pop()] = 0 if log else 1\n",
      "\n",
      "        while len(small):\n",
      "            prob[small.pop()] = 0 if log else 1\n",
      "\n",
      "        self.prob_table = prob\n",
      "        self.alias_table = alias\n",
      "\n",
      "    def __call__(self, n_samples=1):\n",
      "        \"\"\"\n",
      "        Generate random draws from the `probs` distribution over integers in\n",
      "        [0, N).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples: int\n",
      "            The number of samples to generate. Default is 1.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\n",
      "            A collection of draws from the distribution defined by `probs`.\n",
      "            Each sample is an int in the range `[0, N)`.\n",
      "        \"\"\"\n",
      "        return self.sample(n_samples)\n",
      "\n",
      "    def sample(self, n_samples=1):\n",
      "        \"\"\"\n",
      "        Generate random draws from the `probs` distribution over integers in\n",
      "        [0, N).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples: int\n",
      "            The number of samples to generate. Default is 1.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\n",
      "            A collection of draws from the distribution defined by `probs`.\n",
      "            Each sample is an int in the range `[0, N)`.\n",
      "        \"\"\"\n",
      "        ixs = np.random.randint(0, self.N, n_samples)\n",
      "        p = np.exp(self.prob_table[ixs]) if self.log else self.prob_table[ixs]\n",
      "        flips = np.random.binomial(1, p)\n",
      "        samples = [ix if f else self.alias_table[ix] for ix, f in zip(ixs, flips)]\n",
      "\n",
      "        # do recursive rejection sampling to sample without replacement\n",
      "        if not self.with_replacement:\n",
      "            unique = list(set(samples))\n",
      "            while len(samples) != len(unique):\n",
      "                n_new = len(samples) - len(unique)\n",
      "                samples = unique + self.sample(n_new).tolist()\n",
      "                unique = list(set(samples))\n",
      "\n",
      "        return np.array(samples, dtype=int)\n",
      "\n",
      "\n",
      "#######################################################################\n",
      "#                                Dict                                 #\n",
      "#######################################################################\n",
      "\n",
      "\n",
      "class Dict(dict):\n",
      "    def __init__(self, encoder=None):\n",
      "        \"\"\"\n",
      "        A dictionary subclass which returns the key value if it is not in the\n",
      "        dict.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        encoder : function or None\n",
      "            A function which is applied to a key before adding / retrieving it\n",
      "            from the dictionary. If None, the function defaults to the\n",
      "            identity. Default is None.\n",
      "        \"\"\"\n",
      "        super(Dict, self).__init__()\n",
      "        self._encoder = encoder\n",
      "        self._id_max = 0\n",
      "\n",
      "    def __setitem__(self, key, value):\n",
      "        if self._encoder is not None:\n",
      "            key = self._encoder(key)\n",
      "        elif not isinstance(key, Hashable):\n",
      "            key = tuple(key)\n",
      "        super(Dict, self).__setitem__(key, value)\n",
      "\n",
      "    def _encode_key(self, key):\n",
      "        D = super(Dict, self)\n",
      "        enc_key = self._encoder(key)\n",
      "        if D.__contains__(enc_key):\n",
      "            val = D.__getitem__(enc_key)\n",
      "        else:\n",
      "            val = self._id_max\n",
      "            D.__setitem__(enc_key, val)\n",
      "            self._id_max += 1\n",
      "        return val\n",
      "\n",
      "    def __getitem__(self, key):\n",
      "        self._key = copy.deepcopy(key)\n",
      "        if self._encoder is not None:\n",
      "            return self._encode_key(key)\n",
      "        elif not isinstance(key, Hashable):\n",
      "            key = tuple(key)\n",
      "        return super(Dict, self).__getitem__(key)\n",
      "\n",
      "    def __missing__(self, key):\n",
      "        return self._key\n"
     ]
    }
   ],
   "source": [
    "print(content[11513:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_vars': [],\n",
       " 'imports': [('heapq', ('heapq', 543, 548))],\n",
       " 'functions': [('bar', ('def bar():\\n\\tprint(\"Something\")', 438, 468))],\n",
       " 'imports_as': [('np', ('numpy as np', 612, 623))],\n",
       " 'class_def': [('Dict',\n",
       "   ('class Dict(dict):\\n    def __init__(self, encoder=None):\\n        \"\"\"\\n        A dictionary subclass which returns the key value if it is not in the\\n        dict.\\n\\n        Parameters\\n        ----------\\n        encoder : function or None\\n            A function which is applied to a key before adding / retrieving it\\n            from the dictionary. If None, the function defaults to the\\n            identity. Default is None.\\n        \"\"\"\\n        super(Dict, self).__init__()\\n        self._encoder = encoder\\n        self._id_max = 0\\n\\n    def __setitem__(self, key, value):\\n        if self._encoder is not None:\\n            key = self._encoder(key)\\n        elif not isinstance(key, Hashable):\\n            key = tuple(key)\\n        super(Dict, self).__setitem__(key, value)\\n\\n    def _encode_key(self, key):\\n        D = super(Dict, self)\\n        enc_key = self._encoder(key)\\n        if D.__contains__(enc_key):\\n            val = D.__getitem__(enc_key)\\n        else:\\n            val = self._id_max\\n            D.__setitem__(enc_key, val)\\n            self._id_max += 1\\n        return val\\n\\n    def __getitem__(self, key):\\n        self._key = copy.deepcopy(key)\\n        if self._encoder is not None:\\n            return self._encode_key(key)\\n        elif not isinstance(key, Hashable):\\n            key = tuple(key)\\n        return super(Dict, self).__getitem__(key)\\n\\n    def __missing__(self, key):\\n        return self._key',\n",
       "    17566,\n",
       "    18975)),\n",
       "  ('DiscreteSampler',\n",
       "   ('class DiscreteSampler:\\n    def __init__(self, probs, log=False, with_replacement=True):\\n        \"\"\"\\n        Sample from an arbitrary multinomial PMF over the first `N` nonnegative\\n        integers using Vose\\'s algorithm for the alias method.\\n\\n        Notes\\n        -----\\n        Vose\\'s algorithm takes `O(n)` time to initialize, requires `O(n)` memory,\\n        and generates samples in constant time.\\n\\n        References\\n        ----------\\n        .. [1] Walker, A. J. (1977) \"An efficient method for generating discrete\\n           random variables with general distributions\". *ACM Transactions on\\n           Mathematical Software, 3(3)*, 253-256.\\n\\n        .. [2] Vose, M. D. (1991) \"A linear algorithm for generating random numbers\\n           with a given distribution\". *IEEE Trans. Softw. Eng., 9*, 972-974.\\n\\n        .. [3] Schwarz, K (2011) \"Darts, dice, and coins: sampling from a discrete\\n           distribution\". http://www.keithschwarz.com/darts-dice-coins/\\n\\n        Parameters\\n        ----------\\n        probs : :py:class:`ndarray <numpy.ndarray>` of length `(N,)`\\n            A list of probabilities of the `N` outcomes in the sample space.\\n            `probs[i]` returns the probability of outcome `i`.\\n        log : bool\\n            Whether the probabilities in `probs` are in logspace. Default is\\n            False.\\n        with_replacement : bool\\n            Whether to generate samples with or without replacement. Default is\\n            True.\\n        \"\"\"\\n        if not isinstance(probs, np.ndarray):\\n            probs = np.array(probs)\\n\\n        self.log = log\\n        self.N = len(probs)\\n        self.probs = probs\\n        self.with_replacement = with_replacement\\n\\n        alias = np.zeros(self.N)\\n        prob = np.zeros(self.N)\\n        scaled_probs = self.probs + np.log(self.N) if log else self.probs * self.N\\n\\n        selector = scaled_probs < 0 if log else scaled_probs < 1\\n        small, large = np.where(selector)[0].tolist(), np.where(~selector)[0].tolist()\\n\\n        while len(small) and len(large):\\n            l, g = small.pop(), large.pop()\\n\\n            alias[l] = g\\n            prob[l] = scaled_probs[l]\\n\\n            if log:\\n                pg = np.log(np.exp(scaled_probs[g]) + np.exp(scaled_probs[l]) - 1)\\n            else:\\n                pg = scaled_probs[g] + scaled_probs[l] - 1\\n\\n            scaled_probs[g] = pg\\n            to_small = pg < 0 if log else pg < 1\\n            if to_small:\\n                small.append(g)\\n            else:\\n                large.append(g)\\n\\n        while len(large):\\n            prob[large.pop()] = 0 if log else 1\\n\\n        while len(small):\\n            prob[small.pop()] = 0 if log else 1\\n\\n        self.prob_table = prob\\n        self.alias_table = alias\\n\\n    def __call__(self, n_samples=1):\\n        \"\"\"\\n        Generate random draws from the `probs` distribution over integers in\\n        [0, N).\\n\\n        Parameters\\n        ----------\\n        n_samples: int\\n            The number of samples to generate. Default is 1.\\n\\n        Returns\\n        -------\\n        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\\n            A collection of draws from the distribution defined by `probs`.\\n            Each sample is an int in the range `[0, N)`.\\n        \"\"\"\\n        return self.sample(n_samples)\\n\\n    def sample(self, n_samples=1):\\n        \"\"\"\\n        Generate random draws from the `probs` distribution over integers in\\n        [0, N).\\n\\n        Parameters\\n        ----------\\n        n_samples: int\\n            The number of samples to generate. Default is 1.\\n\\n        Returns\\n        -------\\n        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\\n            A collection of draws from the distribution defined by `probs`.\\n            Each sample is an int in the range `[0, N)`.\\n        \"\"\"\\n        ixs = np.random.randint(0, self.N, n_samples)\\n        p = np.exp(self.prob_table[ixs]) if self.log else self.prob_table[ixs]\\n        flips = np.random.binomial(1, p)\\n        samples = [ix if f else self.alias_table[ix] for ix, f in zip(ixs, flips)]\\n\\n        # do recursive rejection sampling to sample without replacement\\n        if not self.with_replacement:\\n            unique = list(set(samples))\\n            while len(samples) != len(unique):\\n                n_new = len(samples) - len(unique)\\n                samples = unique + self.sample(n_new).tolist()\\n                unique = list(set(samples))\\n\\n        return np.array(samples, dtype=int)',\n",
       "    12889,\n",
       "    17345)),\n",
       "  ('PQNode',\n",
       "   ('class PQNode(object):\\n    def __init__(self, key, val, priority, entry_id, **kwargs):\\n        \"\"\"A generic node object for holding entries in :class:`PriorityQueue`\"\"\"\\n        self.key = key\\n        self.val = val\\n        self.entry_id = entry_id\\n        self.priority = priority\\n\\n    def __repr__(self):\\n        fstr = \"PQNode(key={}, val={}, priority={}, entry_id={})\"\\n        return fstr.format(self.key, self.val, self.priority, self.entry_id)\\n\\n    def to_dict(self):\\n        \"\"\"Return a dictionary representation of the node\\'s contents\"\"\"\\n        d = self.__dict__\\n        d[\"id\"] = \"PQNode\"\\n        return d\\n\\n    def __gt__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        if self.priority == other.priority:\\n            return self.entry_id > other.entry_id\\n        return self.priority > other.priority\\n\\n    def __ge__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        return self.priority >= other.priority\\n\\n    def __lt__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        if self.priority == other.priority:\\n            return self.entry_id < other.entry_id\\n        return self.priority < other.priority\\n\\n    def __le__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        return self.priority <= other.priority',\n",
       "    884,\n",
       "    2247)),\n",
       "  ('BallTreeNode',\n",
       "   ('class BallTreeNode:\\n    def __init__(self, centroid=None, X=None, y=None):\\n        self.left = None\\n        self.right = None\\n        self.radius = None\\n        self.is_leaf = False\\n\\n        self.data = X\\n        self.targets = y\\n        self.centroid = centroid\\n\\n    def __repr__(self):\\n        fstr = \"BallTreeNode(centroid={}, is_leaf={})\"\\n        return fstr.format(self.centroid, self.is_leaf)\\n\\n    def to_dict(self):\\n        d = self.__dict__\\n        d[\"id\"] = \"BallTreeNode\"\\n        return d',\n",
       "    6106,\n",
       "    6604)),\n",
       "  ('BallTree',\n",
       "   ('class BallTree:\\n    def __init__(self, leaf_size=40, metric=None):\\n        \"\"\"\\n        A ball tree data structure.\\n\\n        Notes\\n        -----\\n        A ball tree is a binary tree in which every node defines a\\n        `D`-dimensional hypersphere (\"ball\") containing a subset of the points\\n        to be searched. Each internal node of the tree partitions the data\\n        points into two disjoint sets which are associated with different\\n        balls. While the balls themselves may intersect, each point is assigned\\n        to one or the other ball in the partition according to its distance\\n        from the ball\\'s center. Each leaf node in the tree defines a ball and\\n        enumerates all data points inside that ball.\\n\\n        Parameters\\n        ----------\\n        leaf_size : int\\n            The maximum number of datapoints at each leaf. Default is 40.\\n        metric : :doc:`Distance metric <numpy_ml.utils.distance_metrics>` or None\\n            The distance metric to use for computing nearest neighbors. If\\n            None, use the :func:`~numpy_ml.utils.distance_metrics.euclidean`\\n            metric. Default is None.\\n\\n        References\\n        ----------\\n        .. [1] Omohundro, S. M. (1989). \"Five balltree construction algorithms\". *ICSI\\n           Technical Report TR-89-063*.\\n        .. [2] Liu, T., Moore, A., & Gray A. (2006). \"New algorithms for efficient\\n           high-dimensional nonparametric classification\". *J. Mach. Learn. Res.,\\n           7*, 1135-1158.\\n        \"\"\"\\n        self.root = None\\n        self.leaf_size = leaf_size\\n        self.metric = metric if metric is not None else euclidean\\n\\n    def fit(self, X, y=None):\\n        \"\"\"\\n        Build a ball tree recursively using the O(M log N) `k`-d construction\\n        algorithm.\\n\\n        Notes\\n        -----\\n        Recursively divides data into nodes defined by a centroid `C` and radius\\n        `r` such that each point below the node lies within the hyper-sphere\\n        defined by `C` and `r`.\\n\\n        Parameters\\n        ----------\\n        X : :py:class:`ndarray <numpy.ndarray>` of shape `(N, M)`\\n            An array of `N` examples each with `M` features.\\n        y : :py:class:`ndarray <numpy.ndarray>` of shape `(N, \\\\*)` or None\\n            An array of target values / labels associated with the entries in\\n            `X`. Default is None.\\n        \"\"\"\\n        centroid, left_X, left_y, right_X, right_y = self._split(X, y)\\n        self.root = BallTreeNode(centroid=centroid)\\n        self.root.radius = np.max([self.metric(centroid, x) for x in X])\\n        self.root.left = self._build_tree(left_X, left_y)\\n        self.root.right = self._build_tree(right_X, right_y)\\n\\n    def _build_tree(self, X, y):\\n        centroid, left_X, left_y, right_X, right_y = self._split(X, y)\\n\\n        if X.shape[0] <= self.leaf_size:\\n            leaf = BallTreeNode(centroid=centroid, X=X, y=y)\\n            leaf.radius = np.max([self.metric(centroid, x) for x in X])\\n            leaf.is_leaf = True\\n            return leaf\\n\\n        node = BallTreeNode(centroid=centroid)\\n        node.radius = np.max([self.metric(centroid, x) for x in X])\\n        node.left = self._build_tree(left_X, left_y)\\n        node.right = self._build_tree(right_X, right_y)\\n        return node\\n\\n    def _split(self, X, y=None):\\n        # find the dimension with greatest variance\\n        split_dim = np.argmax(np.var(X, axis=0))\\n\\n        # sort X and y along split_dim\\n        sort_ixs = np.argsort(X[:, split_dim])\\n        X, y = X[sort_ixs], y[sort_ixs] if y is not None else None\\n\\n        # divide at median value of split_dim\\n        med_ix = X.shape[0] // 2\\n        centroid = X[med_ix]  # , split_dim\\n\\n        # split data into two halves at the centroid (median always appears on\\n        # the right split)\\n        left_X, left_y = X[:med_ix], y[:med_ix] if y is not None else None\\n        right_X, right_y = X[med_ix:], y[med_ix:] if y is not None else None\\n        return centroid, left_X, left_y, right_X, right_y\\n\\n    def nearest_neighbors(self, k, x):\\n        \"\"\"\\n        Find the `k` nearest neighbors in the ball tree to a query vector `x`\\n        using the KNS1 algorithm.\\n\\n        Parameters\\n        ----------\\n        k : int\\n            The number of closest points in `X` to return\\n        x : :py:class:`ndarray <numpy.ndarray>` of shape `(1, M)`\\n            The query vector.\\n\\n        Returns\\n        -------\\n        nearest : list of :class:`PQNode` s of length `k`\\n            List of the `k` points in `X` to closest to the query vector. The\\n            ``key`` attribute of each :class:`PQNode` contains the point itself, the\\n            ``val`` attribute contains its target, and the ``distance``\\n            attribute contains its distance to the query vector.\\n        \"\"\"\\n        # maintain a max-first priority queue with priority = distance to x\\n        PQ = PriorityQueue(capacity=k, heap_order=\"max\")\\n        nearest = self._knn(k, x, PQ, self.root)\\n        for n in nearest:\\n            n.distance = self.metric(x, n.key)\\n        return nearest\\n\\n    def _knn(self, k, x, PQ, root):\\n        dist = self.metric\\n        dist_to_ball = dist(x, root.centroid) - root.radius\\n        dist_to_farthest_neighbor = dist(x, PQ.peek()[\"key\"]) if len(PQ) > 0 else np.inf\\n\\n        if dist_to_ball >= dist_to_farthest_neighbor and len(PQ) == k:\\n            return PQ\\n        if root.is_leaf:\\n            targets = [None] * len(root.data) if root.targets is None else root.targets\\n            for point, target in zip(root.data, targets):\\n                dist_to_x = dist(x, point)\\n                if len(PQ) == k and dist_to_x < dist_to_farthest_neighbor:\\n                    PQ.push(key=point, val=target, priority=dist_to_x)\\n                else:\\n                    PQ.push(key=point, val=target, priority=dist_to_x)\\n        else:\\n            l_closest = dist(x, root.left.centroid) < dist(x, root.right.centroid)\\n            PQ = self._knn(k, x, PQ, root.left if l_closest else root.right)\\n            PQ = self._knn(k, x, PQ, root.right if l_closest else root.left)\\n        return PQ',\n",
       "    6607,\n",
       "    12668)),\n",
       "  ('PriorityQueue',\n",
       "   ('class PriorityQueue:\\n    def __init__(self, capacity, heap_order=\"max\"):\\n        \"\"\"\\n        A priority queue implementation using a binary heap.\\n\\n        Notes\\n        -----\\n        A priority queue is a data structure useful for storing the top\\n        `capacity` largest or smallest elements in a collection of values. As a\\n        result of using a binary heap, ``PriorityQueue`` offers `O(log N)`\\n        :meth:`push` and :meth:`pop` operations.\\n\\n        Parameters\\n        ----------\\n        capacity: int\\n            The maximum number of items that can be held in the queue.\\n        heap_order: {\"max\", \"min\"}\\n            Whether the priority queue should retain the items with the\\n            `capacity` smallest (`heap_order` = \\'min\\') or `capacity` largest\\n            (`heap_order` = \\'max\\') priorities.\\n        \"\"\"\\n        assert heap_order in [\"max\", \"min\"], \"heap_order must be either \\'max\\' or \\'min\\'\"\\n        self.capacity = capacity\\n        self.heap_order = heap_order\\n\\n        self._pq = []\\n        self._count = 0\\n        self._entry_counter = 0\\n\\n    def __repr__(self):\\n        fstr = \"PriorityQueue(capacity={}, heap_order={}) with {} items\"\\n        return fstr.format(self.capacity, self.heap_order, self._count)\\n\\n    def __len__(self):\\n        return self._count\\n\\n    def __iter__(self):\\n        return iter(self._pq)\\n\\n    def push(self, key, priority, val=None):\\n        \"\"\"\\n        Add a new (key, value) pair with priority `priority` to the queue.\\n\\n        Notes\\n        -----\\n        If the queue is at capacity and `priority` exceeds the priority of the\\n        item with the largest/smallest priority currently in the queue, replace\\n        the current queue item with (`key`, `val`).\\n\\n        Parameters\\n        ----------\\n        key : hashable object\\n            The key to insert into the queue.\\n        priority : comparable\\n            The priority for the `key`, `val` pair.\\n        val : object\\n            The value associated with `key`. Default is None.\\n        \"\"\"\\n        if self.heap_order == \"max\":\\n            priority = -1 * priority\\n\\n        item = PQNode(key=key, val=val, priority=priority, entry_id=self._entry_counter)\\n        heapq.heappush(self._pq, item)\\n\\n        self._count += 1\\n        self._entry_counter += 1\\n\\n        while self._count > self.capacity:\\n            self.pop()\\n\\n    def pop(self):\\n        \"\"\"\\n        Remove the item with the largest/smallest (depending on\\n        ``self.heap_order``) priority from the queue and return it.\\n\\n        Notes\\n        -----\\n        In contrast to :meth:`peek`, this operation is `O(log N)`.\\n\\n        Returns\\n        -------\\n        item : :class:`PQNode` instance or None\\n            Item with the largest/smallest priority, depending on\\n            ``self.heap_order``.\\n        \"\"\"\\n        item = heapq.heappop(self._pq).to_dict()\\n        if self.heap_order == \"max\":\\n            item[\"priority\"] = -1 * item[\"priority\"]\\n        self._count -= 1\\n        return item\\n\\n    def peek(self):\\n        \"\"\"\\n        Return the item with the largest/smallest (depending on\\n        ``self.heap_order``) priority *without* removing it from the queue.\\n\\n        Notes\\n        -----\\n        In contrast to :meth:`pop`, this operation is O(1).\\n\\n        Returns\\n        -------\\n        item : :class:`PQNode` instance or None\\n            Item with the largest/smallest priority, depending on\\n            ``self.heap_order``.\\n        \"\"\"\\n        item = None\\n        if self._count > 0:\\n            item = copy(self._pq[0].to_dict())\\n            if self.heap_order == \"max\":\\n                item[\"priority\"] = -1 * item[\"priority\"]\\n        return item',\n",
       "    2250,\n",
       "    5885))],\n",
       " 'imports_from': [('collections', ('collections', 576, 587)),\n",
       "  ('Hashable', ('Hashable', 595, 603)),\n",
       "  ('copy', ('copy', 566, 570)),\n",
       "  ('copy', ('copy', 554, 558))],\n",
       " 'imports_relative': [('euclidean', ('euclidean', 655, 664))],\n",
       " 'all': [('euclidean', ('euclidean', 655, 664)),\n",
       "  ('collections', ('collections', 576, 587)),\n",
       "  ('Hashable', ('Hashable', 595, 603)),\n",
       "  ('Dict',\n",
       "   ('class Dict(dict):\\n    def __init__(self, encoder=None):\\n        \"\"\"\\n        A dictionary subclass which returns the key value if it is not in the\\n        dict.\\n\\n        Parameters\\n        ----------\\n        encoder : function or None\\n            A function which is applied to a key before adding / retrieving it\\n            from the dictionary. If None, the function defaults to the\\n            identity. Default is None.\\n        \"\"\"\\n        super(Dict, self).__init__()\\n        self._encoder = encoder\\n        self._id_max = 0\\n\\n    def __setitem__(self, key, value):\\n        if self._encoder is not None:\\n            key = self._encoder(key)\\n        elif not isinstance(key, Hashable):\\n            key = tuple(key)\\n        super(Dict, self).__setitem__(key, value)\\n\\n    def _encode_key(self, key):\\n        D = super(Dict, self)\\n        enc_key = self._encoder(key)\\n        if D.__contains__(enc_key):\\n            val = D.__getitem__(enc_key)\\n        else:\\n            val = self._id_max\\n            D.__setitem__(enc_key, val)\\n            self._id_max += 1\\n        return val\\n\\n    def __getitem__(self, key):\\n        self._key = copy.deepcopy(key)\\n        if self._encoder is not None:\\n            return self._encode_key(key)\\n        elif not isinstance(key, Hashable):\\n            key = tuple(key)\\n        return super(Dict, self).__getitem__(key)\\n\\n    def __missing__(self, key):\\n        return self._key',\n",
       "    17566,\n",
       "    18975)),\n",
       "  ('DiscreteSampler',\n",
       "   ('class DiscreteSampler:\\n    def __init__(self, probs, log=False, with_replacement=True):\\n        \"\"\"\\n        Sample from an arbitrary multinomial PMF over the first `N` nonnegative\\n        integers using Vose\\'s algorithm for the alias method.\\n\\n        Notes\\n        -----\\n        Vose\\'s algorithm takes `O(n)` time to initialize, requires `O(n)` memory,\\n        and generates samples in constant time.\\n\\n        References\\n        ----------\\n        .. [1] Walker, A. J. (1977) \"An efficient method for generating discrete\\n           random variables with general distributions\". *ACM Transactions on\\n           Mathematical Software, 3(3)*, 253-256.\\n\\n        .. [2] Vose, M. D. (1991) \"A linear algorithm for generating random numbers\\n           with a given distribution\". *IEEE Trans. Softw. Eng., 9*, 972-974.\\n\\n        .. [3] Schwarz, K (2011) \"Darts, dice, and coins: sampling from a discrete\\n           distribution\". http://www.keithschwarz.com/darts-dice-coins/\\n\\n        Parameters\\n        ----------\\n        probs : :py:class:`ndarray <numpy.ndarray>` of length `(N,)`\\n            A list of probabilities of the `N` outcomes in the sample space.\\n            `probs[i]` returns the probability of outcome `i`.\\n        log : bool\\n            Whether the probabilities in `probs` are in logspace. Default is\\n            False.\\n        with_replacement : bool\\n            Whether to generate samples with or without replacement. Default is\\n            True.\\n        \"\"\"\\n        if not isinstance(probs, np.ndarray):\\n            probs = np.array(probs)\\n\\n        self.log = log\\n        self.N = len(probs)\\n        self.probs = probs\\n        self.with_replacement = with_replacement\\n\\n        alias = np.zeros(self.N)\\n        prob = np.zeros(self.N)\\n        scaled_probs = self.probs + np.log(self.N) if log else self.probs * self.N\\n\\n        selector = scaled_probs < 0 if log else scaled_probs < 1\\n        small, large = np.where(selector)[0].tolist(), np.where(~selector)[0].tolist()\\n\\n        while len(small) and len(large):\\n            l, g = small.pop(), large.pop()\\n\\n            alias[l] = g\\n            prob[l] = scaled_probs[l]\\n\\n            if log:\\n                pg = np.log(np.exp(scaled_probs[g]) + np.exp(scaled_probs[l]) - 1)\\n            else:\\n                pg = scaled_probs[g] + scaled_probs[l] - 1\\n\\n            scaled_probs[g] = pg\\n            to_small = pg < 0 if log else pg < 1\\n            if to_small:\\n                small.append(g)\\n            else:\\n                large.append(g)\\n\\n        while len(large):\\n            prob[large.pop()] = 0 if log else 1\\n\\n        while len(small):\\n            prob[small.pop()] = 0 if log else 1\\n\\n        self.prob_table = prob\\n        self.alias_table = alias\\n\\n    def __call__(self, n_samples=1):\\n        \"\"\"\\n        Generate random draws from the `probs` distribution over integers in\\n        [0, N).\\n\\n        Parameters\\n        ----------\\n        n_samples: int\\n            The number of samples to generate. Default is 1.\\n\\n        Returns\\n        -------\\n        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\\n            A collection of draws from the distribution defined by `probs`.\\n            Each sample is an int in the range `[0, N)`.\\n        \"\"\"\\n        return self.sample(n_samples)\\n\\n    def sample(self, n_samples=1):\\n        \"\"\"\\n        Generate random draws from the `probs` distribution over integers in\\n        [0, N).\\n\\n        Parameters\\n        ----------\\n        n_samples: int\\n            The number of samples to generate. Default is 1.\\n\\n        Returns\\n        -------\\n        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\\n            A collection of draws from the distribution defined by `probs`.\\n            Each sample is an int in the range `[0, N)`.\\n        \"\"\"\\n        ixs = np.random.randint(0, self.N, n_samples)\\n        p = np.exp(self.prob_table[ixs]) if self.log else self.prob_table[ixs]\\n        flips = np.random.binomial(1, p)\\n        samples = [ix if f else self.alias_table[ix] for ix, f in zip(ixs, flips)]\\n\\n        # do recursive rejection sampling to sample without replacement\\n        if not self.with_replacement:\\n            unique = list(set(samples))\\n            while len(samples) != len(unique):\\n                n_new = len(samples) - len(unique)\\n                samples = unique + self.sample(n_new).tolist()\\n                unique = list(set(samples))\\n\\n        return np.array(samples, dtype=int)',\n",
       "    12889,\n",
       "    17345)),\n",
       "  ('copy', ('copy', 566, 570)),\n",
       "  ('PQNode',\n",
       "   ('class PQNode(object):\\n    def __init__(self, key, val, priority, entry_id, **kwargs):\\n        \"\"\"A generic node object for holding entries in :class:`PriorityQueue`\"\"\"\\n        self.key = key\\n        self.val = val\\n        self.entry_id = entry_id\\n        self.priority = priority\\n\\n    def __repr__(self):\\n        fstr = \"PQNode(key={}, val={}, priority={}, entry_id={})\"\\n        return fstr.format(self.key, self.val, self.priority, self.entry_id)\\n\\n    def to_dict(self):\\n        \"\"\"Return a dictionary representation of the node\\'s contents\"\"\"\\n        d = self.__dict__\\n        d[\"id\"] = \"PQNode\"\\n        return d\\n\\n    def __gt__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        if self.priority == other.priority:\\n            return self.entry_id > other.entry_id\\n        return self.priority > other.priority\\n\\n    def __ge__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        return self.priority >= other.priority\\n\\n    def __lt__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        if self.priority == other.priority:\\n            return self.entry_id < other.entry_id\\n        return self.priority < other.priority\\n\\n    def __le__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        return self.priority <= other.priority',\n",
       "    884,\n",
       "    2247)),\n",
       "  ('BallTreeNode',\n",
       "   ('class BallTreeNode:\\n    def __init__(self, centroid=None, X=None, y=None):\\n        self.left = None\\n        self.right = None\\n        self.radius = None\\n        self.is_leaf = False\\n\\n        self.data = X\\n        self.targets = y\\n        self.centroid = centroid\\n\\n    def __repr__(self):\\n        fstr = \"BallTreeNode(centroid={}, is_leaf={})\"\\n        return fstr.format(self.centroid, self.is_leaf)\\n\\n    def to_dict(self):\\n        d = self.__dict__\\n        d[\"id\"] = \"BallTreeNode\"\\n        return d',\n",
       "    6106,\n",
       "    6604)),\n",
       "  ('bar', ('def bar():\\n\\tprint(\"Something\")', 438, 468)),\n",
       "  ('heapq', ('heapq', 543, 548)),\n",
       "  ('copy', ('copy', 554, 558)),\n",
       "  ('BallTree',\n",
       "   ('class BallTree:\\n    def __init__(self, leaf_size=40, metric=None):\\n        \"\"\"\\n        A ball tree data structure.\\n\\n        Notes\\n        -----\\n        A ball tree is a binary tree in which every node defines a\\n        `D`-dimensional hypersphere (\"ball\") containing a subset of the points\\n        to be searched. Each internal node of the tree partitions the data\\n        points into two disjoint sets which are associated with different\\n        balls. While the balls themselves may intersect, each point is assigned\\n        to one or the other ball in the partition according to its distance\\n        from the ball\\'s center. Each leaf node in the tree defines a ball and\\n        enumerates all data points inside that ball.\\n\\n        Parameters\\n        ----------\\n        leaf_size : int\\n            The maximum number of datapoints at each leaf. Default is 40.\\n        metric : :doc:`Distance metric <numpy_ml.utils.distance_metrics>` or None\\n            The distance metric to use for computing nearest neighbors. If\\n            None, use the :func:`~numpy_ml.utils.distance_metrics.euclidean`\\n            metric. Default is None.\\n\\n        References\\n        ----------\\n        .. [1] Omohundro, S. M. (1989). \"Five balltree construction algorithms\". *ICSI\\n           Technical Report TR-89-063*.\\n        .. [2] Liu, T., Moore, A., & Gray A. (2006). \"New algorithms for efficient\\n           high-dimensional nonparametric classification\". *J. Mach. Learn. Res.,\\n           7*, 1135-1158.\\n        \"\"\"\\n        self.root = None\\n        self.leaf_size = leaf_size\\n        self.metric = metric if metric is not None else euclidean\\n\\n    def fit(self, X, y=None):\\n        \"\"\"\\n        Build a ball tree recursively using the O(M log N) `k`-d construction\\n        algorithm.\\n\\n        Notes\\n        -----\\n        Recursively divides data into nodes defined by a centroid `C` and radius\\n        `r` such that each point below the node lies within the hyper-sphere\\n        defined by `C` and `r`.\\n\\n        Parameters\\n        ----------\\n        X : :py:class:`ndarray <numpy.ndarray>` of shape `(N, M)`\\n            An array of `N` examples each with `M` features.\\n        y : :py:class:`ndarray <numpy.ndarray>` of shape `(N, \\\\*)` or None\\n            An array of target values / labels associated with the entries in\\n            `X`. Default is None.\\n        \"\"\"\\n        centroid, left_X, left_y, right_X, right_y = self._split(X, y)\\n        self.root = BallTreeNode(centroid=centroid)\\n        self.root.radius = np.max([self.metric(centroid, x) for x in X])\\n        self.root.left = self._build_tree(left_X, left_y)\\n        self.root.right = self._build_tree(right_X, right_y)\\n\\n    def _build_tree(self, X, y):\\n        centroid, left_X, left_y, right_X, right_y = self._split(X, y)\\n\\n        if X.shape[0] <= self.leaf_size:\\n            leaf = BallTreeNode(centroid=centroid, X=X, y=y)\\n            leaf.radius = np.max([self.metric(centroid, x) for x in X])\\n            leaf.is_leaf = True\\n            return leaf\\n\\n        node = BallTreeNode(centroid=centroid)\\n        node.radius = np.max([self.metric(centroid, x) for x in X])\\n        node.left = self._build_tree(left_X, left_y)\\n        node.right = self._build_tree(right_X, right_y)\\n        return node\\n\\n    def _split(self, X, y=None):\\n        # find the dimension with greatest variance\\n        split_dim = np.argmax(np.var(X, axis=0))\\n\\n        # sort X and y along split_dim\\n        sort_ixs = np.argsort(X[:, split_dim])\\n        X, y = X[sort_ixs], y[sort_ixs] if y is not None else None\\n\\n        # divide at median value of split_dim\\n        med_ix = X.shape[0] // 2\\n        centroid = X[med_ix]  # , split_dim\\n\\n        # split data into two halves at the centroid (median always appears on\\n        # the right split)\\n        left_X, left_y = X[:med_ix], y[:med_ix] if y is not None else None\\n        right_X, right_y = X[med_ix:], y[med_ix:] if y is not None else None\\n        return centroid, left_X, left_y, right_X, right_y\\n\\n    def nearest_neighbors(self, k, x):\\n        \"\"\"\\n        Find the `k` nearest neighbors in the ball tree to a query vector `x`\\n        using the KNS1 algorithm.\\n\\n        Parameters\\n        ----------\\n        k : int\\n            The number of closest points in `X` to return\\n        x : :py:class:`ndarray <numpy.ndarray>` of shape `(1, M)`\\n            The query vector.\\n\\n        Returns\\n        -------\\n        nearest : list of :class:`PQNode` s of length `k`\\n            List of the `k` points in `X` to closest to the query vector. The\\n            ``key`` attribute of each :class:`PQNode` contains the point itself, the\\n            ``val`` attribute contains its target, and the ``distance``\\n            attribute contains its distance to the query vector.\\n        \"\"\"\\n        # maintain a max-first priority queue with priority = distance to x\\n        PQ = PriorityQueue(capacity=k, heap_order=\"max\")\\n        nearest = self._knn(k, x, PQ, self.root)\\n        for n in nearest:\\n            n.distance = self.metric(x, n.key)\\n        return nearest\\n\\n    def _knn(self, k, x, PQ, root):\\n        dist = self.metric\\n        dist_to_ball = dist(x, root.centroid) - root.radius\\n        dist_to_farthest_neighbor = dist(x, PQ.peek()[\"key\"]) if len(PQ) > 0 else np.inf\\n\\n        if dist_to_ball >= dist_to_farthest_neighbor and len(PQ) == k:\\n            return PQ\\n        if root.is_leaf:\\n            targets = [None] * len(root.data) if root.targets is None else root.targets\\n            for point, target in zip(root.data, targets):\\n                dist_to_x = dist(x, point)\\n                if len(PQ) == k and dist_to_x < dist_to_farthest_neighbor:\\n                    PQ.push(key=point, val=target, priority=dist_to_x)\\n                else:\\n                    PQ.push(key=point, val=target, priority=dist_to_x)\\n        else:\\n            l_closest = dist(x, root.left.centroid) < dist(x, root.right.centroid)\\n            PQ = self._knn(k, x, PQ, root.left if l_closest else root.right)\\n            PQ = self._knn(k, x, PQ, root.right if l_closest else root.left)\\n        return PQ',\n",
       "    6607,\n",
       "    12668)),\n",
       "  ('np', ('numpy as np', 612, 623)),\n",
       "  ('PriorityQueue',\n",
       "   ('class PriorityQueue:\\n    def __init__(self, capacity, heap_order=\"max\"):\\n        \"\"\"\\n        A priority queue implementation using a binary heap.\\n\\n        Notes\\n        -----\\n        A priority queue is a data structure useful for storing the top\\n        `capacity` largest or smallest elements in a collection of values. As a\\n        result of using a binary heap, ``PriorityQueue`` offers `O(log N)`\\n        :meth:`push` and :meth:`pop` operations.\\n\\n        Parameters\\n        ----------\\n        capacity: int\\n            The maximum number of items that can be held in the queue.\\n        heap_order: {\"max\", \"min\"}\\n            Whether the priority queue should retain the items with the\\n            `capacity` smallest (`heap_order` = \\'min\\') or `capacity` largest\\n            (`heap_order` = \\'max\\') priorities.\\n        \"\"\"\\n        assert heap_order in [\"max\", \"min\"], \"heap_order must be either \\'max\\' or \\'min\\'\"\\n        self.capacity = capacity\\n        self.heap_order = heap_order\\n\\n        self._pq = []\\n        self._count = 0\\n        self._entry_counter = 0\\n\\n    def __repr__(self):\\n        fstr = \"PriorityQueue(capacity={}, heap_order={}) with {} items\"\\n        return fstr.format(self.capacity, self.heap_order, self._count)\\n\\n    def __len__(self):\\n        return self._count\\n\\n    def __iter__(self):\\n        return iter(self._pq)\\n\\n    def push(self, key, priority, val=None):\\n        \"\"\"\\n        Add a new (key, value) pair with priority `priority` to the queue.\\n\\n        Notes\\n        -----\\n        If the queue is at capacity and `priority` exceeds the priority of the\\n        item with the largest/smallest priority currently in the queue, replace\\n        the current queue item with (`key`, `val`).\\n\\n        Parameters\\n        ----------\\n        key : hashable object\\n            The key to insert into the queue.\\n        priority : comparable\\n            The priority for the `key`, `val` pair.\\n        val : object\\n            The value associated with `key`. Default is None.\\n        \"\"\"\\n        if self.heap_order == \"max\":\\n            priority = -1 * priority\\n\\n        item = PQNode(key=key, val=val, priority=priority, entry_id=self._entry_counter)\\n        heapq.heappush(self._pq, item)\\n\\n        self._count += 1\\n        self._entry_counter += 1\\n\\n        while self._count > self.capacity:\\n            self.pop()\\n\\n    def pop(self):\\n        \"\"\"\\n        Remove the item with the largest/smallest (depending on\\n        ``self.heap_order``) priority from the queue and return it.\\n\\n        Notes\\n        -----\\n        In contrast to :meth:`peek`, this operation is `O(log N)`.\\n\\n        Returns\\n        -------\\n        item : :class:`PQNode` instance or None\\n            Item with the largest/smallest priority, depending on\\n            ``self.heap_order``.\\n        \"\"\"\\n        item = heapq.heappop(self._pq).to_dict()\\n        if self.heap_order == \"max\":\\n            item[\"priority\"] = -1 * item[\"priority\"]\\n        self._count -= 1\\n        return item\\n\\n    def peek(self):\\n        \"\"\"\\n        Return the item with the largest/smallest (depending on\\n        ``self.heap_order``) priority *without* removing it from the queue.\\n\\n        Notes\\n        -----\\n        In contrast to :meth:`pop`, this operation is O(1).\\n\\n        Returns\\n        -------\\n        item : :class:`PQNode` instance or None\\n            Item with the largest/smallest priority, depending on\\n            ``self.heap_order``.\\n        \"\"\"\\n        item = None\\n        if self._count > 0:\\n            item = copy(self._pq[0].to_dict())\\n            if self.heap_order == \"max\":\\n                item[\"priority\"] = -1 * item[\"priority\"]\\n        return item',\n",
       "    2250,\n",
       "    5885))]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_symbols(content)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "model_path = '/Users/zkcpku/Documents/seke/mywork/ROPE/Llama-2-7b-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"I am a student\",\n",
    "    \"I am a teacher\",\n",
    "    \"I am a doctor and I am a teacher\",\n",
    "    \"I am a student and I am a teacher\",\n",
    "    \"I\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 306, 626, 263, 8368],\n",
       " [1, 306, 626, 263, 15703],\n",
       " [1, 306, 626, 263, 11619, 322, 306, 626, 263, 15703],\n",
       " [1, 306, 626, 263, 8368, 322, 306, 626, 263, 15703],\n",
       " [1, 306]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(text, padding=False).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
