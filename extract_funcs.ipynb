{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from autocomplete import extract_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"code_example.py\",'r') as f:\n",
    "    content = f.read()\n",
    "    # rst = extract(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._knn(k, x, PQ, self.root)\n",
      "        for n in nearest:\n",
      "            n.distance = self.metric(x, n.key)\n",
      "        return nearest\n",
      "\n",
      "    def _knn(self, k, x, PQ, root):\n",
      "        dist = self.metric\n",
      "        dist_to_ball = dist(x, root.centroid) - root.radius\n",
      "        dist_to_farthest_neighbor = dist(x, PQ.peek()[\"key\"]) if len(PQ) > 0 else np.inf\n",
      "\n",
      "        if dist_to_ball >= dist_to_farthest_neighbor and len(PQ) == k:\n",
      "            return PQ\n",
      "        if root.is_leaf:\n",
      "            targets = [None] * len(root.data) if root.targets is None else root.targets\n",
      "            for point, target in zip(root.data, targets):\n",
      "                dist_to_x = dist(x, point)\n",
      "                if len(PQ) == k and dist_to_x < dist_to_farthest_neighbor:\n",
      "                    PQ.push(key=point, val=target, priority=dist_to_x)\n",
      "                else:\n",
      "                    PQ.push(key=point, val=target, priority=dist_to_x)\n",
      "        else:\n",
      "            l_closest = dist(x, root.left.centroid) < dist(x, root.right.centroid)\n",
      "            PQ = self._knn(k, x, PQ, root.left if l_closest else root.right)\n",
      "            PQ = self._knn(k, x, PQ, root.right if l_closest else root.left)\n",
      "        return PQ\n",
      "\n",
      "\n",
      "#######################################################################\n",
      "#                         Multinomial Sampler                         #\n",
      "#######################################################################\n",
      "\n",
      "\n",
      "class DiscreteSampler:\n",
      "    def __init__(self, probs, log=False, with_replacement=True):\n",
      "        \"\"\"\n",
      "        Sample from an arbitrary multinomial PMF over the first `N` nonnegative\n",
      "        integers using Vose's algorithm for the alias method.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Vose's algorithm takes `O(n)` time to initialize, requires `O(n)` memory,\n",
      "        and generates samples in constant time.\n",
      "\n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Walker, A. J. (1977) \"An efficient method for generating discrete\n",
      "           random variables with general distributions\". *ACM Transactions on\n",
      "           Mathematical Software, 3(3)*, 253-256.\n",
      "\n",
      "        .. [2] Vose, M. D. (1991) \"A linear algorithm for generating random numbers\n",
      "           with a given distribution\". *IEEE Trans. Softw. Eng., 9*, 972-974.\n",
      "\n",
      "        .. [3] Schwarz, K (2011) \"Darts, dice, and coins: sampling from a discrete\n",
      "           distribution\". http://www.keithschwarz.com/darts-dice-coins/\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        probs : :py:class:`ndarray <numpy.ndarray>` of length `(N,)`\n",
      "            A list of probabilities of the `N` outcomes in the sample space.\n",
      "            `probs[i]` returns the probability of outcome `i`.\n",
      "        log : bool\n",
      "            Whether the probabilities in `probs` are in logspace. Default is\n",
      "            False.\n",
      "        with_replacement : bool\n",
      "            Whether to generate samples with or without replacement. Default is\n",
      "            True.\n",
      "        \"\"\"\n",
      "        if not isinstance(probs, np.ndarray):\n",
      "            probs = np.array(probs)\n",
      "\n",
      "        self.log = log\n",
      "        self.N = len(probs)\n",
      "        self.probs = probs\n",
      "        self.with_replacement = with_replacement\n",
      "\n",
      "        alias = np.zeros(self.N)\n",
      "        prob = np.zeros(self.N)\n",
      "        scaled_probs = self.probs + np.log(self.N) if log else self.probs * self.N\n",
      "\n",
      "        selector = scaled_probs < 0 if log else scaled_probs < 1\n",
      "        small, large = np.where(selector)[0].tolist(), np.where(~selector)[0].tolist()\n",
      "\n",
      "        while len(small) and len(large):\n",
      "            l, g = small.pop(), large.pop()\n",
      "\n",
      "            alias[l] = g\n",
      "            prob[l] = scaled_probs[l]\n",
      "\n",
      "            if log:\n",
      "                pg = np.log(np.exp(scaled_probs[g]) + np.exp(scaled_probs[l]) - 1)\n",
      "            else:\n",
      "                pg = scaled_probs[g] + scaled_probs[l] - 1\n",
      "\n",
      "            scaled_probs[g] = pg\n",
      "            to_small = pg < 0 if log else pg < 1\n",
      "            if to_small:\n",
      "                small.append(g)\n",
      "            else:\n",
      "                large.append(g)\n",
      "\n",
      "        while len(large):\n",
      "            prob[large.pop()] = 0 if log else 1\n",
      "\n",
      "        while len(small):\n",
      "            prob[small.pop()] = 0 if log else 1\n",
      "\n",
      "        self.prob_table = prob\n",
      "        self.alias_table = alias\n",
      "\n",
      "    def __call__(self, n_samples=1):\n",
      "        \"\"\"\n",
      "        Generate random draws from the `probs` distribution over integers in\n",
      "        [0, N).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples: int\n",
      "            The number of samples to generate. Default is 1.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\n",
      "            A collection of draws from the distribution defined by `probs`.\n",
      "            Each sample is an int in the range `[0, N)`.\n",
      "        \"\"\"\n",
      "        return self.sample(n_samples)\n",
      "\n",
      "    def sample(self, n_samples=1):\n",
      "        \"\"\"\n",
      "        Generate random draws from the `probs` distribution over integers in\n",
      "        [0, N).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples: int\n",
      "            The number of samples to generate. Default is 1.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\n",
      "            A collection of draws from the distribution defined by `probs`.\n",
      "            Each sample is an int in the range `[0, N)`.\n",
      "        \"\"\"\n",
      "        ixs = np.random.randint(0, self.N, n_samples)\n",
      "        p = np.exp(self.prob_table[ixs]) if self.log else self.prob_table[ixs]\n",
      "        flips = np.random.binomial(1, p)\n",
      "        samples = [ix if f else self.alias_table[ix] for ix, f in zip(ixs, flips)]\n",
      "\n",
      "        # do recursive rejection sampling to sample without replacement\n",
      "        if not self.with_replacement:\n",
      "            unique = list(set(samples))\n",
      "            while len(samples) != len(unique):\n",
      "                n_new = len(samples) - len(unique)\n",
      "                samples = unique + self.sample(n_new).tolist()\n",
      "                unique = list(set(samples))\n",
      "\n",
      "        return np.array(samples, dtype=int)\n",
      "\n",
      "\n",
      "#######################################################################\n",
      "#                                Dict                                 #\n",
      "#######################################################################\n",
      "\n",
      "\n",
      "class Dict(dict):\n",
      "    def __init__(self, encoder=None):\n",
      "        \"\"\"\n",
      "        A dictionary subclass which returns the key value if it is not in the\n",
      "        dict.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        encoder : function or None\n",
      "            A function which is applied to a key before adding / retrieving it\n",
      "            from the dictionary. If None, the function defaults to the\n",
      "            identity. Default is None.\n",
      "        \"\"\"\n",
      "        super(Dict, self).__init__()\n",
      "        self._encoder = encoder\n",
      "        self._id_max = 0\n",
      "\n",
      "    def __setitem__(self, key, value):\n",
      "        if self._encoder is not None:\n",
      "            key = self._encoder(key)\n",
      "        elif not isinstance(key, Hashable):\n",
      "            key = tuple(key)\n",
      "        super(Dict, self).__setitem__(key, value)\n",
      "\n",
      "    def _encode_key(self, key):\n",
      "        D = super(Dict, self)\n",
      "        enc_key = self._encoder(key)\n",
      "        if D.__contains__(enc_key):\n",
      "            val = D.__getitem__(enc_key)\n",
      "        else:\n",
      "            val = self._id_max\n",
      "            D.__setitem__(enc_key, val)\n",
      "            self._id_max += 1\n",
      "        return val\n",
      "\n",
      "    def __getitem__(self, key):\n",
      "        self._key = copy.deepcopy(key)\n",
      "        if self._encoder is not None:\n",
      "            return self._encode_key(key)\n",
      "        elif not isinstance(key, Hashable):\n",
      "            key = tuple(key)\n",
      "        return super(Dict, self).__getitem__(key)\n",
      "\n",
      "    def __missing__(self, key):\n",
      "        return self._key\n"
     ]
    }
   ],
   "source": [
    "print(content[11513:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_vars': [],\n",
       " 'imports': [('heapq', ('heapq', 543, 548))],\n",
       " 'functions': [('bar', ('def bar():\\n\\tprint(\"Something\")', 438, 468))],\n",
       " 'imports_as': [('np', ('numpy as np', 612, 623))],\n",
       " 'class_def': [('Dict',\n",
       "   ('class Dict(dict):\\n    def __init__(self, encoder=None):\\n        \"\"\"\\n        A dictionary subclass which returns the key value if it is not in the\\n        dict.\\n\\n        Parameters\\n        ----------\\n        encoder : function or None\\n            A function which is applied to a key before adding / retrieving it\\n            from the dictionary. If None, the function defaults to the\\n            identity. Default is None.\\n        \"\"\"\\n        super(Dict, self).__init__()\\n        self._encoder = encoder\\n        self._id_max = 0\\n\\n    def __setitem__(self, key, value):\\n        if self._encoder is not None:\\n            key = self._encoder(key)\\n        elif not isinstance(key, Hashable):\\n            key = tuple(key)\\n        super(Dict, self).__setitem__(key, value)\\n\\n    def _encode_key(self, key):\\n        D = super(Dict, self)\\n        enc_key = self._encoder(key)\\n        if D.__contains__(enc_key):\\n            val = D.__getitem__(enc_key)\\n        else:\\n            val = self._id_max\\n            D.__setitem__(enc_key, val)\\n            self._id_max += 1\\n        return val\\n\\n    def __getitem__(self, key):\\n        self._key = copy.deepcopy(key)\\n        if self._encoder is not None:\\n            return self._encode_key(key)\\n        elif not isinstance(key, Hashable):\\n            key = tuple(key)\\n        return super(Dict, self).__getitem__(key)\\n\\n    def __missing__(self, key):\\n        return self._key',\n",
       "    17566,\n",
       "    18975)),\n",
       "  ('DiscreteSampler',\n",
       "   ('class DiscreteSampler:\\n    def __init__(self, probs, log=False, with_replacement=True):\\n        \"\"\"\\n        Sample from an arbitrary multinomial PMF over the first `N` nonnegative\\n        integers using Vose\\'s algorithm for the alias method.\\n\\n        Notes\\n        -----\\n        Vose\\'s algorithm takes `O(n)` time to initialize, requires `O(n)` memory,\\n        and generates samples in constant time.\\n\\n        References\\n        ----------\\n        .. [1] Walker, A. J. (1977) \"An efficient method for generating discrete\\n           random variables with general distributions\". *ACM Transactions on\\n           Mathematical Software, 3(3)*, 253-256.\\n\\n        .. [2] Vose, M. D. (1991) \"A linear algorithm for generating random numbers\\n           with a given distribution\". *IEEE Trans. Softw. Eng., 9*, 972-974.\\n\\n        .. [3] Schwarz, K (2011) \"Darts, dice, and coins: sampling from a discrete\\n           distribution\". http://www.keithschwarz.com/darts-dice-coins/\\n\\n        Parameters\\n        ----------\\n        probs : :py:class:`ndarray <numpy.ndarray>` of length `(N,)`\\n            A list of probabilities of the `N` outcomes in the sample space.\\n            `probs[i]` returns the probability of outcome `i`.\\n        log : bool\\n            Whether the probabilities in `probs` are in logspace. Default is\\n            False.\\n        with_replacement : bool\\n            Whether to generate samples with or without replacement. Default is\\n            True.\\n        \"\"\"\\n        if not isinstance(probs, np.ndarray):\\n            probs = np.array(probs)\\n\\n        self.log = log\\n        self.N = len(probs)\\n        self.probs = probs\\n        self.with_replacement = with_replacement\\n\\n        alias = np.zeros(self.N)\\n        prob = np.zeros(self.N)\\n        scaled_probs = self.probs + np.log(self.N) if log else self.probs * self.N\\n\\n        selector = scaled_probs < 0 if log else scaled_probs < 1\\n        small, large = np.where(selector)[0].tolist(), np.where(~selector)[0].tolist()\\n\\n        while len(small) and len(large):\\n            l, g = small.pop(), large.pop()\\n\\n            alias[l] = g\\n            prob[l] = scaled_probs[l]\\n\\n            if log:\\n                pg = np.log(np.exp(scaled_probs[g]) + np.exp(scaled_probs[l]) - 1)\\n            else:\\n                pg = scaled_probs[g] + scaled_probs[l] - 1\\n\\n            scaled_probs[g] = pg\\n            to_small = pg < 0 if log else pg < 1\\n            if to_small:\\n                small.append(g)\\n            else:\\n                large.append(g)\\n\\n        while len(large):\\n            prob[large.pop()] = 0 if log else 1\\n\\n        while len(small):\\n            prob[small.pop()] = 0 if log else 1\\n\\n        self.prob_table = prob\\n        self.alias_table = alias\\n\\n    def __call__(self, n_samples=1):\\n        \"\"\"\\n        Generate random draws from the `probs` distribution over integers in\\n        [0, N).\\n\\n        Parameters\\n        ----------\\n        n_samples: int\\n            The number of samples to generate. Default is 1.\\n\\n        Returns\\n        -------\\n        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\\n            A collection of draws from the distribution defined by `probs`.\\n            Each sample is an int in the range `[0, N)`.\\n        \"\"\"\\n        return self.sample(n_samples)\\n\\n    def sample(self, n_samples=1):\\n        \"\"\"\\n        Generate random draws from the `probs` distribution over integers in\\n        [0, N).\\n\\n        Parameters\\n        ----------\\n        n_samples: int\\n            The number of samples to generate. Default is 1.\\n\\n        Returns\\n        -------\\n        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\\n            A collection of draws from the distribution defined by `probs`.\\n            Each sample is an int in the range `[0, N)`.\\n        \"\"\"\\n        ixs = np.random.randint(0, self.N, n_samples)\\n        p = np.exp(self.prob_table[ixs]) if self.log else self.prob_table[ixs]\\n        flips = np.random.binomial(1, p)\\n        samples = [ix if f else self.alias_table[ix] for ix, f in zip(ixs, flips)]\\n\\n        # do recursive rejection sampling to sample without replacement\\n        if not self.with_replacement:\\n            unique = list(set(samples))\\n            while len(samples) != len(unique):\\n                n_new = len(samples) - len(unique)\\n                samples = unique + self.sample(n_new).tolist()\\n                unique = list(set(samples))\\n\\n        return np.array(samples, dtype=int)',\n",
       "    12889,\n",
       "    17345)),\n",
       "  ('PQNode',\n",
       "   ('class PQNode(object):\\n    def __init__(self, key, val, priority, entry_id, **kwargs):\\n        \"\"\"A generic node object for holding entries in :class:`PriorityQueue`\"\"\"\\n        self.key = key\\n        self.val = val\\n        self.entry_id = entry_id\\n        self.priority = priority\\n\\n    def __repr__(self):\\n        fstr = \"PQNode(key={}, val={}, priority={}, entry_id={})\"\\n        return fstr.format(self.key, self.val, self.priority, self.entry_id)\\n\\n    def to_dict(self):\\n        \"\"\"Return a dictionary representation of the node\\'s contents\"\"\"\\n        d = self.__dict__\\n        d[\"id\"] = \"PQNode\"\\n        return d\\n\\n    def __gt__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        if self.priority == other.priority:\\n            return self.entry_id > other.entry_id\\n        return self.priority > other.priority\\n\\n    def __ge__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        return self.priority >= other.priority\\n\\n    def __lt__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        if self.priority == other.priority:\\n            return self.entry_id < other.entry_id\\n        return self.priority < other.priority\\n\\n    def __le__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        return self.priority <= other.priority',\n",
       "    884,\n",
       "    2247)),\n",
       "  ('BallTreeNode',\n",
       "   ('class BallTreeNode:\\n    def __init__(self, centroid=None, X=None, y=None):\\n        self.left = None\\n        self.right = None\\n        self.radius = None\\n        self.is_leaf = False\\n\\n        self.data = X\\n        self.targets = y\\n        self.centroid = centroid\\n\\n    def __repr__(self):\\n        fstr = \"BallTreeNode(centroid={}, is_leaf={})\"\\n        return fstr.format(self.centroid, self.is_leaf)\\n\\n    def to_dict(self):\\n        d = self.__dict__\\n        d[\"id\"] = \"BallTreeNode\"\\n        return d',\n",
       "    6106,\n",
       "    6604)),\n",
       "  ('BallTree',\n",
       "   ('class BallTree:\\n    def __init__(self, leaf_size=40, metric=None):\\n        \"\"\"\\n        A ball tree data structure.\\n\\n        Notes\\n        -----\\n        A ball tree is a binary tree in which every node defines a\\n        `D`-dimensional hypersphere (\"ball\") containing a subset of the points\\n        to be searched. Each internal node of the tree partitions the data\\n        points into two disjoint sets which are associated with different\\n        balls. While the balls themselves may intersect, each point is assigned\\n        to one or the other ball in the partition according to its distance\\n        from the ball\\'s center. Each leaf node in the tree defines a ball and\\n        enumerates all data points inside that ball.\\n\\n        Parameters\\n        ----------\\n        leaf_size : int\\n            The maximum number of datapoints at each leaf. Default is 40.\\n        metric : :doc:`Distance metric <numpy_ml.utils.distance_metrics>` or None\\n            The distance metric to use for computing nearest neighbors. If\\n            None, use the :func:`~numpy_ml.utils.distance_metrics.euclidean`\\n            metric. Default is None.\\n\\n        References\\n        ----------\\n        .. [1] Omohundro, S. M. (1989). \"Five balltree construction algorithms\". *ICSI\\n           Technical Report TR-89-063*.\\n        .. [2] Liu, T., Moore, A., & Gray A. (2006). \"New algorithms for efficient\\n           high-dimensional nonparametric classification\". *J. Mach. Learn. Res.,\\n           7*, 1135-1158.\\n        \"\"\"\\n        self.root = None\\n        self.leaf_size = leaf_size\\n        self.metric = metric if metric is not None else euclidean\\n\\n    def fit(self, X, y=None):\\n        \"\"\"\\n        Build a ball tree recursively using the O(M log N) `k`-d construction\\n        algorithm.\\n\\n        Notes\\n        -----\\n        Recursively divides data into nodes defined by a centroid `C` and radius\\n        `r` such that each point below the node lies within the hyper-sphere\\n        defined by `C` and `r`.\\n\\n        Parameters\\n        ----------\\n        X : :py:class:`ndarray <numpy.ndarray>` of shape `(N, M)`\\n            An array of `N` examples each with `M` features.\\n        y : :py:class:`ndarray <numpy.ndarray>` of shape `(N, \\\\*)` or None\\n            An array of target values / labels associated with the entries in\\n            `X`. Default is None.\\n        \"\"\"\\n        centroid, left_X, left_y, right_X, right_y = self._split(X, y)\\n        self.root = BallTreeNode(centroid=centroid)\\n        self.root.radius = np.max([self.metric(centroid, x) for x in X])\\n        self.root.left = self._build_tree(left_X, left_y)\\n        self.root.right = self._build_tree(right_X, right_y)\\n\\n    def _build_tree(self, X, y):\\n        centroid, left_X, left_y, right_X, right_y = self._split(X, y)\\n\\n        if X.shape[0] <= self.leaf_size:\\n            leaf = BallTreeNode(centroid=centroid, X=X, y=y)\\n            leaf.radius = np.max([self.metric(centroid, x) for x in X])\\n            leaf.is_leaf = True\\n            return leaf\\n\\n        node = BallTreeNode(centroid=centroid)\\n        node.radius = np.max([self.metric(centroid, x) for x in X])\\n        node.left = self._build_tree(left_X, left_y)\\n        node.right = self._build_tree(right_X, right_y)\\n        return node\\n\\n    def _split(self, X, y=None):\\n        # find the dimension with greatest variance\\n        split_dim = np.argmax(np.var(X, axis=0))\\n\\n        # sort X and y along split_dim\\n        sort_ixs = np.argsort(X[:, split_dim])\\n        X, y = X[sort_ixs], y[sort_ixs] if y is not None else None\\n\\n        # divide at median value of split_dim\\n        med_ix = X.shape[0] // 2\\n        centroid = X[med_ix]  # , split_dim\\n\\n        # split data into two halves at the centroid (median always appears on\\n        # the right split)\\n        left_X, left_y = X[:med_ix], y[:med_ix] if y is not None else None\\n        right_X, right_y = X[med_ix:], y[med_ix:] if y is not None else None\\n        return centroid, left_X, left_y, right_X, right_y\\n\\n    def nearest_neighbors(self, k, x):\\n        \"\"\"\\n        Find the `k` nearest neighbors in the ball tree to a query vector `x`\\n        using the KNS1 algorithm.\\n\\n        Parameters\\n        ----------\\n        k : int\\n            The number of closest points in `X` to return\\n        x : :py:class:`ndarray <numpy.ndarray>` of shape `(1, M)`\\n            The query vector.\\n\\n        Returns\\n        -------\\n        nearest : list of :class:`PQNode` s of length `k`\\n            List of the `k` points in `X` to closest to the query vector. The\\n            ``key`` attribute of each :class:`PQNode` contains the point itself, the\\n            ``val`` attribute contains its target, and the ``distance``\\n            attribute contains its distance to the query vector.\\n        \"\"\"\\n        # maintain a max-first priority queue with priority = distance to x\\n        PQ = PriorityQueue(capacity=k, heap_order=\"max\")\\n        nearest = self._knn(k, x, PQ, self.root)\\n        for n in nearest:\\n            n.distance = self.metric(x, n.key)\\n        return nearest\\n\\n    def _knn(self, k, x, PQ, root):\\n        dist = self.metric\\n        dist_to_ball = dist(x, root.centroid) - root.radius\\n        dist_to_farthest_neighbor = dist(x, PQ.peek()[\"key\"]) if len(PQ) > 0 else np.inf\\n\\n        if dist_to_ball >= dist_to_farthest_neighbor and len(PQ) == k:\\n            return PQ\\n        if root.is_leaf:\\n            targets = [None] * len(root.data) if root.targets is None else root.targets\\n            for point, target in zip(root.data, targets):\\n                dist_to_x = dist(x, point)\\n                if len(PQ) == k and dist_to_x < dist_to_farthest_neighbor:\\n                    PQ.push(key=point, val=target, priority=dist_to_x)\\n                else:\\n                    PQ.push(key=point, val=target, priority=dist_to_x)\\n        else:\\n            l_closest = dist(x, root.left.centroid) < dist(x, root.right.centroid)\\n            PQ = self._knn(k, x, PQ, root.left if l_closest else root.right)\\n            PQ = self._knn(k, x, PQ, root.right if l_closest else root.left)\\n        return PQ',\n",
       "    6607,\n",
       "    12668)),\n",
       "  ('PriorityQueue',\n",
       "   ('class PriorityQueue:\\n    def __init__(self, capacity, heap_order=\"max\"):\\n        \"\"\"\\n        A priority queue implementation using a binary heap.\\n\\n        Notes\\n        -----\\n        A priority queue is a data structure useful for storing the top\\n        `capacity` largest or smallest elements in a collection of values. As a\\n        result of using a binary heap, ``PriorityQueue`` offers `O(log N)`\\n        :meth:`push` and :meth:`pop` operations.\\n\\n        Parameters\\n        ----------\\n        capacity: int\\n            The maximum number of items that can be held in the queue.\\n        heap_order: {\"max\", \"min\"}\\n            Whether the priority queue should retain the items with the\\n            `capacity` smallest (`heap_order` = \\'min\\') or `capacity` largest\\n            (`heap_order` = \\'max\\') priorities.\\n        \"\"\"\\n        assert heap_order in [\"max\", \"min\"], \"heap_order must be either \\'max\\' or \\'min\\'\"\\n        self.capacity = capacity\\n        self.heap_order = heap_order\\n\\n        self._pq = []\\n        self._count = 0\\n        self._entry_counter = 0\\n\\n    def __repr__(self):\\n        fstr = \"PriorityQueue(capacity={}, heap_order={}) with {} items\"\\n        return fstr.format(self.capacity, self.heap_order, self._count)\\n\\n    def __len__(self):\\n        return self._count\\n\\n    def __iter__(self):\\n        return iter(self._pq)\\n\\n    def push(self, key, priority, val=None):\\n        \"\"\"\\n        Add a new (key, value) pair with priority `priority` to the queue.\\n\\n        Notes\\n        -----\\n        If the queue is at capacity and `priority` exceeds the priority of the\\n        item with the largest/smallest priority currently in the queue, replace\\n        the current queue item with (`key`, `val`).\\n\\n        Parameters\\n        ----------\\n        key : hashable object\\n            The key to insert into the queue.\\n        priority : comparable\\n            The priority for the `key`, `val` pair.\\n        val : object\\n            The value associated with `key`. Default is None.\\n        \"\"\"\\n        if self.heap_order == \"max\":\\n            priority = -1 * priority\\n\\n        item = PQNode(key=key, val=val, priority=priority, entry_id=self._entry_counter)\\n        heapq.heappush(self._pq, item)\\n\\n        self._count += 1\\n        self._entry_counter += 1\\n\\n        while self._count > self.capacity:\\n            self.pop()\\n\\n    def pop(self):\\n        \"\"\"\\n        Remove the item with the largest/smallest (depending on\\n        ``self.heap_order``) priority from the queue and return it.\\n\\n        Notes\\n        -----\\n        In contrast to :meth:`peek`, this operation is `O(log N)`.\\n\\n        Returns\\n        -------\\n        item : :class:`PQNode` instance or None\\n            Item with the largest/smallest priority, depending on\\n            ``self.heap_order``.\\n        \"\"\"\\n        item = heapq.heappop(self._pq).to_dict()\\n        if self.heap_order == \"max\":\\n            item[\"priority\"] = -1 * item[\"priority\"]\\n        self._count -= 1\\n        return item\\n\\n    def peek(self):\\n        \"\"\"\\n        Return the item with the largest/smallest (depending on\\n        ``self.heap_order``) priority *without* removing it from the queue.\\n\\n        Notes\\n        -----\\n        In contrast to :meth:`pop`, this operation is O(1).\\n\\n        Returns\\n        -------\\n        item : :class:`PQNode` instance or None\\n            Item with the largest/smallest priority, depending on\\n            ``self.heap_order``.\\n        \"\"\"\\n        item = None\\n        if self._count > 0:\\n            item = copy(self._pq[0].to_dict())\\n            if self.heap_order == \"max\":\\n                item[\"priority\"] = -1 * item[\"priority\"]\\n        return item',\n",
       "    2250,\n",
       "    5885))],\n",
       " 'imports_from': [('collections', ('collections', 576, 587)),\n",
       "  ('Hashable', ('Hashable', 595, 603)),\n",
       "  ('copy', ('copy', 566, 570)),\n",
       "  ('copy', ('copy', 554, 558))],\n",
       " 'imports_relative': [('euclidean', ('euclidean', 655, 664))],\n",
       " 'all': [('euclidean', ('euclidean', 655, 664)),\n",
       "  ('collections', ('collections', 576, 587)),\n",
       "  ('Hashable', ('Hashable', 595, 603)),\n",
       "  ('Dict',\n",
       "   ('class Dict(dict):\\n    def __init__(self, encoder=None):\\n        \"\"\"\\n        A dictionary subclass which returns the key value if it is not in the\\n        dict.\\n\\n        Parameters\\n        ----------\\n        encoder : function or None\\n            A function which is applied to a key before adding / retrieving it\\n            from the dictionary. If None, the function defaults to the\\n            identity. Default is None.\\n        \"\"\"\\n        super(Dict, self).__init__()\\n        self._encoder = encoder\\n        self._id_max = 0\\n\\n    def __setitem__(self, key, value):\\n        if self._encoder is not None:\\n            key = self._encoder(key)\\n        elif not isinstance(key, Hashable):\\n            key = tuple(key)\\n        super(Dict, self).__setitem__(key, value)\\n\\n    def _encode_key(self, key):\\n        D = super(Dict, self)\\n        enc_key = self._encoder(key)\\n        if D.__contains__(enc_key):\\n            val = D.__getitem__(enc_key)\\n        else:\\n            val = self._id_max\\n            D.__setitem__(enc_key, val)\\n            self._id_max += 1\\n        return val\\n\\n    def __getitem__(self, key):\\n        self._key = copy.deepcopy(key)\\n        if self._encoder is not None:\\n            return self._encode_key(key)\\n        elif not isinstance(key, Hashable):\\n            key = tuple(key)\\n        return super(Dict, self).__getitem__(key)\\n\\n    def __missing__(self, key):\\n        return self._key',\n",
       "    17566,\n",
       "    18975)),\n",
       "  ('DiscreteSampler',\n",
       "   ('class DiscreteSampler:\\n    def __init__(self, probs, log=False, with_replacement=True):\\n        \"\"\"\\n        Sample from an arbitrary multinomial PMF over the first `N` nonnegative\\n        integers using Vose\\'s algorithm for the alias method.\\n\\n        Notes\\n        -----\\n        Vose\\'s algorithm takes `O(n)` time to initialize, requires `O(n)` memory,\\n        and generates samples in constant time.\\n\\n        References\\n        ----------\\n        .. [1] Walker, A. J. (1977) \"An efficient method for generating discrete\\n           random variables with general distributions\". *ACM Transactions on\\n           Mathematical Software, 3(3)*, 253-256.\\n\\n        .. [2] Vose, M. D. (1991) \"A linear algorithm for generating random numbers\\n           with a given distribution\". *IEEE Trans. Softw. Eng., 9*, 972-974.\\n\\n        .. [3] Schwarz, K (2011) \"Darts, dice, and coins: sampling from a discrete\\n           distribution\". http://www.keithschwarz.com/darts-dice-coins/\\n\\n        Parameters\\n        ----------\\n        probs : :py:class:`ndarray <numpy.ndarray>` of length `(N,)`\\n            A list of probabilities of the `N` outcomes in the sample space.\\n            `probs[i]` returns the probability of outcome `i`.\\n        log : bool\\n            Whether the probabilities in `probs` are in logspace. Default is\\n            False.\\n        with_replacement : bool\\n            Whether to generate samples with or without replacement. Default is\\n            True.\\n        \"\"\"\\n        if not isinstance(probs, np.ndarray):\\n            probs = np.array(probs)\\n\\n        self.log = log\\n        self.N = len(probs)\\n        self.probs = probs\\n        self.with_replacement = with_replacement\\n\\n        alias = np.zeros(self.N)\\n        prob = np.zeros(self.N)\\n        scaled_probs = self.probs + np.log(self.N) if log else self.probs * self.N\\n\\n        selector = scaled_probs < 0 if log else scaled_probs < 1\\n        small, large = np.where(selector)[0].tolist(), np.where(~selector)[0].tolist()\\n\\n        while len(small) and len(large):\\n            l, g = small.pop(), large.pop()\\n\\n            alias[l] = g\\n            prob[l] = scaled_probs[l]\\n\\n            if log:\\n                pg = np.log(np.exp(scaled_probs[g]) + np.exp(scaled_probs[l]) - 1)\\n            else:\\n                pg = scaled_probs[g] + scaled_probs[l] - 1\\n\\n            scaled_probs[g] = pg\\n            to_small = pg < 0 if log else pg < 1\\n            if to_small:\\n                small.append(g)\\n            else:\\n                large.append(g)\\n\\n        while len(large):\\n            prob[large.pop()] = 0 if log else 1\\n\\n        while len(small):\\n            prob[small.pop()] = 0 if log else 1\\n\\n        self.prob_table = prob\\n        self.alias_table = alias\\n\\n    def __call__(self, n_samples=1):\\n        \"\"\"\\n        Generate random draws from the `probs` distribution over integers in\\n        [0, N).\\n\\n        Parameters\\n        ----------\\n        n_samples: int\\n            The number of samples to generate. Default is 1.\\n\\n        Returns\\n        -------\\n        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\\n            A collection of draws from the distribution defined by `probs`.\\n            Each sample is an int in the range `[0, N)`.\\n        \"\"\"\\n        return self.sample(n_samples)\\n\\n    def sample(self, n_samples=1):\\n        \"\"\"\\n        Generate random draws from the `probs` distribution over integers in\\n        [0, N).\\n\\n        Parameters\\n        ----------\\n        n_samples: int\\n            The number of samples to generate. Default is 1.\\n\\n        Returns\\n        -------\\n        sample : :py:class:`ndarray <numpy.ndarray>` of shape `(n_samples,)`\\n            A collection of draws from the distribution defined by `probs`.\\n            Each sample is an int in the range `[0, N)`.\\n        \"\"\"\\n        ixs = np.random.randint(0, self.N, n_samples)\\n        p = np.exp(self.prob_table[ixs]) if self.log else self.prob_table[ixs]\\n        flips = np.random.binomial(1, p)\\n        samples = [ix if f else self.alias_table[ix] for ix, f in zip(ixs, flips)]\\n\\n        # do recursive rejection sampling to sample without replacement\\n        if not self.with_replacement:\\n            unique = list(set(samples))\\n            while len(samples) != len(unique):\\n                n_new = len(samples) - len(unique)\\n                samples = unique + self.sample(n_new).tolist()\\n                unique = list(set(samples))\\n\\n        return np.array(samples, dtype=int)',\n",
       "    12889,\n",
       "    17345)),\n",
       "  ('copy', ('copy', 566, 570)),\n",
       "  ('PQNode',\n",
       "   ('class PQNode(object):\\n    def __init__(self, key, val, priority, entry_id, **kwargs):\\n        \"\"\"A generic node object for holding entries in :class:`PriorityQueue`\"\"\"\\n        self.key = key\\n        self.val = val\\n        self.entry_id = entry_id\\n        self.priority = priority\\n\\n    def __repr__(self):\\n        fstr = \"PQNode(key={}, val={}, priority={}, entry_id={})\"\\n        return fstr.format(self.key, self.val, self.priority, self.entry_id)\\n\\n    def to_dict(self):\\n        \"\"\"Return a dictionary representation of the node\\'s contents\"\"\"\\n        d = self.__dict__\\n        d[\"id\"] = \"PQNode\"\\n        return d\\n\\n    def __gt__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        if self.priority == other.priority:\\n            return self.entry_id > other.entry_id\\n        return self.priority > other.priority\\n\\n    def __ge__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        return self.priority >= other.priority\\n\\n    def __lt__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        if self.priority == other.priority:\\n            return self.entry_id < other.entry_id\\n        return self.priority < other.priority\\n\\n    def __le__(self, other):\\n        if not isinstance(other, PQNode):\\n            return -1\\n        return self.priority <= other.priority',\n",
       "    884,\n",
       "    2247)),\n",
       "  ('BallTreeNode',\n",
       "   ('class BallTreeNode:\\n    def __init__(self, centroid=None, X=None, y=None):\\n        self.left = None\\n        self.right = None\\n        self.radius = None\\n        self.is_leaf = False\\n\\n        self.data = X\\n        self.targets = y\\n        self.centroid = centroid\\n\\n    def __repr__(self):\\n        fstr = \"BallTreeNode(centroid={}, is_leaf={})\"\\n        return fstr.format(self.centroid, self.is_leaf)\\n\\n    def to_dict(self):\\n        d = self.__dict__\\n        d[\"id\"] = \"BallTreeNode\"\\n        return d',\n",
       "    6106,\n",
       "    6604)),\n",
       "  ('bar', ('def bar():\\n\\tprint(\"Something\")', 438, 468)),\n",
       "  ('heapq', ('heapq', 543, 548)),\n",
       "  ('copy', ('copy', 554, 558)),\n",
       "  ('BallTree',\n",
       "   ('class BallTree:\\n    def __init__(self, leaf_size=40, metric=None):\\n        \"\"\"\\n        A ball tree data structure.\\n\\n        Notes\\n        -----\\n        A ball tree is a binary tree in which every node defines a\\n        `D`-dimensional hypersphere (\"ball\") containing a subset of the points\\n        to be searched. Each internal node of the tree partitions the data\\n        points into two disjoint sets which are associated with different\\n        balls. While the balls themselves may intersect, each point is assigned\\n        to one or the other ball in the partition according to its distance\\n        from the ball\\'s center. Each leaf node in the tree defines a ball and\\n        enumerates all data points inside that ball.\\n\\n        Parameters\\n        ----------\\n        leaf_size : int\\n            The maximum number of datapoints at each leaf. Default is 40.\\n        metric : :doc:`Distance metric <numpy_ml.utils.distance_metrics>` or None\\n            The distance metric to use for computing nearest neighbors. If\\n            None, use the :func:`~numpy_ml.utils.distance_metrics.euclidean`\\n            metric. Default is None.\\n\\n        References\\n        ----------\\n        .. [1] Omohundro, S. M. (1989). \"Five balltree construction algorithms\". *ICSI\\n           Technical Report TR-89-063*.\\n        .. [2] Liu, T., Moore, A., & Gray A. (2006). \"New algorithms for efficient\\n           high-dimensional nonparametric classification\". *J. Mach. Learn. Res.,\\n           7*, 1135-1158.\\n        \"\"\"\\n        self.root = None\\n        self.leaf_size = leaf_size\\n        self.metric = metric if metric is not None else euclidean\\n\\n    def fit(self, X, y=None):\\n        \"\"\"\\n        Build a ball tree recursively using the O(M log N) `k`-d construction\\n        algorithm.\\n\\n        Notes\\n        -----\\n        Recursively divides data into nodes defined by a centroid `C` and radius\\n        `r` such that each point below the node lies within the hyper-sphere\\n        defined by `C` and `r`.\\n\\n        Parameters\\n        ----------\\n        X : :py:class:`ndarray <numpy.ndarray>` of shape `(N, M)`\\n            An array of `N` examples each with `M` features.\\n        y : :py:class:`ndarray <numpy.ndarray>` of shape `(N, \\\\*)` or None\\n            An array of target values / labels associated with the entries in\\n            `X`. Default is None.\\n        \"\"\"\\n        centroid, left_X, left_y, right_X, right_y = self._split(X, y)\\n        self.root = BallTreeNode(centroid=centroid)\\n        self.root.radius = np.max([self.metric(centroid, x) for x in X])\\n        self.root.left = self._build_tree(left_X, left_y)\\n        self.root.right = self._build_tree(right_X, right_y)\\n\\n    def _build_tree(self, X, y):\\n        centroid, left_X, left_y, right_X, right_y = self._split(X, y)\\n\\n        if X.shape[0] <= self.leaf_size:\\n            leaf = BallTreeNode(centroid=centroid, X=X, y=y)\\n            leaf.radius = np.max([self.metric(centroid, x) for x in X])\\n            leaf.is_leaf = True\\n            return leaf\\n\\n        node = BallTreeNode(centroid=centroid)\\n        node.radius = np.max([self.metric(centroid, x) for x in X])\\n        node.left = self._build_tree(left_X, left_y)\\n        node.right = self._build_tree(right_X, right_y)\\n        return node\\n\\n    def _split(self, X, y=None):\\n        # find the dimension with greatest variance\\n        split_dim = np.argmax(np.var(X, axis=0))\\n\\n        # sort X and y along split_dim\\n        sort_ixs = np.argsort(X[:, split_dim])\\n        X, y = X[sort_ixs], y[sort_ixs] if y is not None else None\\n\\n        # divide at median value of split_dim\\n        med_ix = X.shape[0] // 2\\n        centroid = X[med_ix]  # , split_dim\\n\\n        # split data into two halves at the centroid (median always appears on\\n        # the right split)\\n        left_X, left_y = X[:med_ix], y[:med_ix] if y is not None else None\\n        right_X, right_y = X[med_ix:], y[med_ix:] if y is not None else None\\n        return centroid, left_X, left_y, right_X, right_y\\n\\n    def nearest_neighbors(self, k, x):\\n        \"\"\"\\n        Find the `k` nearest neighbors in the ball tree to a query vector `x`\\n        using the KNS1 algorithm.\\n\\n        Parameters\\n        ----------\\n        k : int\\n            The number of closest points in `X` to return\\n        x : :py:class:`ndarray <numpy.ndarray>` of shape `(1, M)`\\n            The query vector.\\n\\n        Returns\\n        -------\\n        nearest : list of :class:`PQNode` s of length `k`\\n            List of the `k` points in `X` to closest to the query vector. The\\n            ``key`` attribute of each :class:`PQNode` contains the point itself, the\\n            ``val`` attribute contains its target, and the ``distance``\\n            attribute contains its distance to the query vector.\\n        \"\"\"\\n        # maintain a max-first priority queue with priority = distance to x\\n        PQ = PriorityQueue(capacity=k, heap_order=\"max\")\\n        nearest = self._knn(k, x, PQ, self.root)\\n        for n in nearest:\\n            n.distance = self.metric(x, n.key)\\n        return nearest\\n\\n    def _knn(self, k, x, PQ, root):\\n        dist = self.metric\\n        dist_to_ball = dist(x, root.centroid) - root.radius\\n        dist_to_farthest_neighbor = dist(x, PQ.peek()[\"key\"]) if len(PQ) > 0 else np.inf\\n\\n        if dist_to_ball >= dist_to_farthest_neighbor and len(PQ) == k:\\n            return PQ\\n        if root.is_leaf:\\n            targets = [None] * len(root.data) if root.targets is None else root.targets\\n            for point, target in zip(root.data, targets):\\n                dist_to_x = dist(x, point)\\n                if len(PQ) == k and dist_to_x < dist_to_farthest_neighbor:\\n                    PQ.push(key=point, val=target, priority=dist_to_x)\\n                else:\\n                    PQ.push(key=point, val=target, priority=dist_to_x)\\n        else:\\n            l_closest = dist(x, root.left.centroid) < dist(x, root.right.centroid)\\n            PQ = self._knn(k, x, PQ, root.left if l_closest else root.right)\\n            PQ = self._knn(k, x, PQ, root.right if l_closest else root.left)\\n        return PQ',\n",
       "    6607,\n",
       "    12668)),\n",
       "  ('np', ('numpy as np', 612, 623)),\n",
       "  ('PriorityQueue',\n",
       "   ('class PriorityQueue:\\n    def __init__(self, capacity, heap_order=\"max\"):\\n        \"\"\"\\n        A priority queue implementation using a binary heap.\\n\\n        Notes\\n        -----\\n        A priority queue is a data structure useful for storing the top\\n        `capacity` largest or smallest elements in a collection of values. As a\\n        result of using a binary heap, ``PriorityQueue`` offers `O(log N)`\\n        :meth:`push` and :meth:`pop` operations.\\n\\n        Parameters\\n        ----------\\n        capacity: int\\n            The maximum number of items that can be held in the queue.\\n        heap_order: {\"max\", \"min\"}\\n            Whether the priority queue should retain the items with the\\n            `capacity` smallest (`heap_order` = \\'min\\') or `capacity` largest\\n            (`heap_order` = \\'max\\') priorities.\\n        \"\"\"\\n        assert heap_order in [\"max\", \"min\"], \"heap_order must be either \\'max\\' or \\'min\\'\"\\n        self.capacity = capacity\\n        self.heap_order = heap_order\\n\\n        self._pq = []\\n        self._count = 0\\n        self._entry_counter = 0\\n\\n    def __repr__(self):\\n        fstr = \"PriorityQueue(capacity={}, heap_order={}) with {} items\"\\n        return fstr.format(self.capacity, self.heap_order, self._count)\\n\\n    def __len__(self):\\n        return self._count\\n\\n    def __iter__(self):\\n        return iter(self._pq)\\n\\n    def push(self, key, priority, val=None):\\n        \"\"\"\\n        Add a new (key, value) pair with priority `priority` to the queue.\\n\\n        Notes\\n        -----\\n        If the queue is at capacity and `priority` exceeds the priority of the\\n        item with the largest/smallest priority currently in the queue, replace\\n        the current queue item with (`key`, `val`).\\n\\n        Parameters\\n        ----------\\n        key : hashable object\\n            The key to insert into the queue.\\n        priority : comparable\\n            The priority for the `key`, `val` pair.\\n        val : object\\n            The value associated with `key`. Default is None.\\n        \"\"\"\\n        if self.heap_order == \"max\":\\n            priority = -1 * priority\\n\\n        item = PQNode(key=key, val=val, priority=priority, entry_id=self._entry_counter)\\n        heapq.heappush(self._pq, item)\\n\\n        self._count += 1\\n        self._entry_counter += 1\\n\\n        while self._count > self.capacity:\\n            self.pop()\\n\\n    def pop(self):\\n        \"\"\"\\n        Remove the item with the largest/smallest (depending on\\n        ``self.heap_order``) priority from the queue and return it.\\n\\n        Notes\\n        -----\\n        In contrast to :meth:`peek`, this operation is `O(log N)`.\\n\\n        Returns\\n        -------\\n        item : :class:`PQNode` instance or None\\n            Item with the largest/smallest priority, depending on\\n            ``self.heap_order``.\\n        \"\"\"\\n        item = heapq.heappop(self._pq).to_dict()\\n        if self.heap_order == \"max\":\\n            item[\"priority\"] = -1 * item[\"priority\"]\\n        self._count -= 1\\n        return item\\n\\n    def peek(self):\\n        \"\"\"\\n        Return the item with the largest/smallest (depending on\\n        ``self.heap_order``) priority *without* removing it from the queue.\\n\\n        Notes\\n        -----\\n        In contrast to :meth:`pop`, this operation is O(1).\\n\\n        Returns\\n        -------\\n        item : :class:`PQNode` instance or None\\n            Item with the largest/smallest priority, depending on\\n            ``self.heap_order``.\\n        \"\"\"\\n        item = None\\n        if self._count > 0:\\n            item = copy(self._pq[0].to_dict())\\n            if self.heap_order == \"max\":\\n                item[\"priority\"] = -1 * item[\"priority\"]\\n        return item',\n",
       "    2250,\n",
       "    5885))]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_symbols(content)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "model_path = '/Users/zkcpku/Documents/seke/mywork/分块ROPE/Llama-2-7b-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"I am a student\",\n",
    "    \"I am a teacher\",\n",
    "    \"I am a doctor and I am a teacher\",\n",
    "    \"I am a student and I am a teacher\",\n",
    "    \"I\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 306, 626, 263, 8368],\n",
       " [1, 306, 626, 263, 15703],\n",
       " [1, 306, 626, 263, 11619, 322, 306, 626, 263, 15703],\n",
       " [1, 306, 626, 263, 8368, 322, 306, 626, 263, 15703],\n",
       " [1, 306]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(text, padding=False).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "inp_path = '/Users/zkcpku/Documents/seke/mywork/分块ROPE/openai_src/codesymbols_outputless100.jsonl'\n",
    "out_path = '/Users/zkcpku/Documents/seke/mywork/分块ROPE/openai_src/codesymbols_outputless100.jsoncontext.jsonl'\n",
    "with open(inp_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [json.loads(x) for x in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '\"\"\"Chain that takes in an input and produces an action and action input.\"\"\"\\nfrom __future__ import annotations\\n\\nimport asyncio\\nimport json\\nimport logging\\nimport time\\nfrom abc import abstractmethod\\nfrom pathlib import Path\\nfrom typing import (\\n    Any,\\n    AsyncIterator,\\n    Callable,\\n    Dict,\\n    Iterator,\\n    List,\\n    Optional,\\n    Sequence,\\n    Tuple,\\n    Union,\\n)\\n\\nimport yaml\\nfrom langchain_core._api import deprecated\\nfrom langchain_core.agents import AgentAction, AgentFinish, AgentStep\\nfrom langchain_core.callbacks import (\\n    AsyncCallbackManagerForChainRun,\\n    AsyncCallbackManagerForToolRun,\\n    BaseCallbackManager,\\n    CallbackManagerForChainRun,\\n    CallbackManagerForToolRun,\\n    Callbacks,\\n)\\nfrom langchain_core.exceptions import OutputParserException\\nfrom langchain_core.language_models import BaseLanguageModel\\nfrom langchain_core.messages import BaseMessage\\nfrom langchain_core.output_parsers import BaseOutputParser\\nfrom langchain_core.prompts import BasePromptTemplate\\nfrom langchain_core.prompts.few_shot import FewShotPromptTemplate\\nfrom langchain_core.prompts.prompt import PromptTemplate\\nfrom langchain_core.pydantic_v1 import BaseModel, root_validator\\nfrom langchain_core.runnables import Runnable, RunnableConfig, ensure_config\\nfrom langchain_core.runnables.utils import AddableDict\\nfrom langchain_core.tools import BaseTool\\nfrom langchain_core.utils.input import get_color_mapping\\n\\nfrom langchain.agents.agent_iterator import AgentExecutorIterator\\nfrom langchain.agents.agent_types import AgentType\\nfrom langchain.agents.tools import InvalidTool\\nfrom langchain.chains.base import Chain\\nfrom langchain.chains.llm import LLMChain\\nfrom langchain.utilities.asyncio import asyncio_timeout\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\nclass BaseSingleActionAgent(BaseModel):\\n    \"\"\"Base Single Action Agent class.\"\"\"\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        \"\"\"Return values of the agent.\"\"\"\\n        return [\"output\"]\\n\\n    def get_allowed_tools(self) -> Optional[List[str]]:\\n        return None\\n\\n    @abstractmethod\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n\\n    @abstractmethod\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n\\n    @property\\n    @abstractmethod\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        :meta private:\\n        \"\"\"\\n\\n    def return_stopped_response(\\n        self,\\n        early_stopping_method: str,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        **kwargs: Any,\\n    ) -> AgentFinish:\\n        \"\"\"Return response when agent has been stopped due to max iterations.\"\"\"\\n        if early_stopping_method == \"force\":\\n            # `force` just returns a constant string\\n            return AgentFinish(\\n                {\"output\": \"Agent stopped due to iteration limit or time limit.\"}, \"\"\\n            )\\n        else:\\n            raise ValueError(\\n                f\"Got unsupported early_stopping_method `{early_stopping_method}`\"\\n            )\\n\\n    @classmethod\\n    def from_llm_and_tools(\\n        cls,\\n        llm: BaseLanguageModel,\\n        tools: Sequence[BaseTool],\\n        callback_manager: Optional[BaseCallbackManager] = None,\\n        **kwargs: Any,\\n    ) -> BaseSingleActionAgent:\\n        raise NotImplementedError\\n\\n    @property\\n    def _agent_type(self) -> str:\\n        \"\"\"Return Identifier of agent type.\"\"\"\\n        raise NotImplementedError\\n\\n    def dict(self, **kwargs: Any) -> Dict:\\n        \"\"\"Return dictionary representation of agent.\"\"\"\\n        _dict = super().dict()\\n        try:\\n            _type = self._agent_type\\n        except NotImplementedError:\\n            _type = None\\n        if isinstance(_type, AgentType):\\n            _dict[\"_type\"] = str(_type.value)\\n        elif _type is not None:\\n            _dict[\"_type\"] = _type\\n        return _dict\\n\\n    def save(self, file_path: Union[Path, str]) -> None:\\n        \"\"\"Save the agent.\\n\\n        Args:\\n            file_path: Path to file to save the agent to.\\n\\n        Example:\\n        .. code-block:: python\\n\\n            # If working with agent executor\\n            agent.agent.save(file_path=\"path/agent.yaml\")\\n        \"\"\"\\n        # Convert file to Path object.\\n        if isinstance(file_path, str):\\n            save_path = Path(file_path)\\n        else:\\n            save_path = file_path\\n\\n        directory_path = save_path.parent\\n        directory_path.mkdir(parents=True, exist_ok=True)\\n\\n        # Fetch dictionary to save\\n        agent_dict = self.dict()\\n        if \"_type\" not in agent_dict:\\n            raise NotImplementedError(f\"Agent {self} does not support saving\")\\n\\n        if save_path.suffix == \".json\":\\n            with open(file_path, \"w\") as f:\\n                json.dump(agent_dict, f, indent=4)\\n        elif save_path.suffix == \".yaml\":\\n            with open(file_path, \"w\") as f:\\n                yaml.dump(agent_dict, f, default_flow_style=False)\\n        else:\\n            raise ValueError(f\"{save_path} must be json or yaml\")\\n\\n    def tool_run_logging_kwargs(self) -> Dict:\\n        return {}\\n\\n\\nclass BaseMultiActionAgent(BaseModel):\\n    \"\"\"Base Multi Action Agent class.\"\"\"\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        \"\"\"Return values of the agent.\"\"\"\\n        return [\"output\"]\\n\\n    def get_allowed_tools(self) -> Optional[List[str]]:\\n        return None\\n\\n    @abstractmethod\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[List[AgentAction], AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Actions specifying what tool to use.\\n        \"\"\"\\n\\n    @abstractmethod\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[List[AgentAction], AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Actions specifying what tool to use.\\n        \"\"\"\\n\\n    @property\\n    @abstractmethod\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        :meta private:\\n        \"\"\"\\n\\n    def return_stopped_response(\\n        self,\\n        early_stopping_method: str,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        **kwargs: Any,\\n    ) -> AgentFinish:\\n        \"\"\"Return response when agent has been stopped due to max iterations.\"\"\"\\n        if early_stopping_method == \"force\":\\n            # `force` just returns a constant string\\n            return AgentFinish({\"output\": \"Agent stopped due to max iterations.\"}, \"\")\\n        else:\\n            raise ValueError(\\n                f\"Got unsupported early_stopping_method `{early_stopping_method}`\"\\n            )\\n\\n    @property\\n    def _agent_type(self) -> str:\\n        \"\"\"Return Identifier of agent type.\"\"\"\\n        raise NotImplementedError\\n\\n    def dict(self, **kwargs: Any) -> Dict:\\n        \"\"\"Return dictionary representation of agent.\"\"\"\\n        _dict = super().dict()\\n        try:\\n            _dict[\"_type\"] = str(self._agent_type)\\n        except NotImplementedError:\\n            pass\\n        return _dict\\n\\n    def save(self, file_path: Union[Path, str]) -> None:\\n        \"\"\"Save the agent.\\n\\n        Args:\\n            file_path: Path to file to save the agent to.\\n\\n        Example:\\n        .. code-block:: python\\n\\n            # If working with agent executor\\n            agent.agent.save(file_path=\"path/agent.yaml\")\\n        \"\"\"\\n        # Convert file to Path object.\\n        if isinstance(file_path, str):\\n            save_path = Path(file_path)\\n        else:\\n            save_path = file_path\\n\\n        # Fetch dictionary to save\\n        agent_dict = self.dict()\\n        if \"_type\" not in agent_dict:\\n            raise NotImplementedError(f\"Agent {self} does not support saving.\")\\n\\n        directory_path = save_path.parent\\n        directory_path.mkdir(parents=True, exist_ok=True)\\n\\n        if save_path.suffix == \".json\":\\n            with open(file_path, \"w\") as f:\\n                json.dump(agent_dict, f, indent=4)\\n        elif save_path.suffix == \".yaml\":\\n            with open(file_path, \"w\") as f:\\n                yaml.dump(agent_dict, f, default_flow_style=False)\\n        else:\\n            raise ValueError(f\"{save_path} must be json or yaml\")\\n\\n    def tool_run_logging_kwargs(self) -> Dict:\\n        return {}\\n\\n\\nclass AgentOutputParser(BaseOutputParser[Union[AgentAction, AgentFinish]]):\\n    \"\"\"Base class for parsing agent output into agent action/finish.\"\"\"\\n\\n    @abstractmethod\\n    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Parse text into agent action/finish.\"\"\"\\n\\n\\nclass MultiActionAgentOutputParser(\\n    BaseOutputParser[Union[List[AgentAction], AgentFinish]]\\n):\\n    \"\"\"Base class for parsing agent output into agent actions/finish.\"\"\"\\n\\n    @abstractmethod\\n    def parse(self, text: str) -> Union[List[AgentAction], AgentFinish]:\\n        \"\"\"Parse text into agent actions/finish.\"\"\"\\n\\n\\nclass RunnableAgent(BaseSingleActionAgent):\\n    \"\"\"Agent powered by runnables.\"\"\"\\n\\n    runnable: Runnable[dict, Union[AgentAction, AgentFinish]]\\n    \"\"\"Runnable to call to get agent action.\"\"\"\\n    input_keys_arg: List[str] = []\\n    return_keys_arg: List[str] = []\\n\\n    class Config:\\n        \"\"\"Configuration for this pydantic object.\"\"\"\\n\\n        arbitrary_types_allowed = True\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        \"\"\"Return values of the agent.\"\"\"\\n        return self.return_keys_arg\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        return self.input_keys_arg\\n\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Based on past history and current inputs, decide what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        inputs = {**kwargs, **{\"intermediate_steps\": intermediate_steps}}\\n        # Use streaming to make sure that the underlying LLM is invoked in a streaming\\n        # fashion to make it possible to get access to the individual LLM tokens\\n        # when using stream_log with the Agent Executor.\\n        # Because the response from the plan is not a generator, we need to\\n        # accumulate the output into final output and return that.\\n        final_output: Any = None\\n        for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}):\\n            if final_output is None:\\n                final_output = chunk\\n            else:\\n                final_output += chunk\\n\\n        return final_output\\n\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[\\n        AgentAction,\\n        AgentFinish,\\n    ]:\\n        \"\"\"Based on past history and current inputs, decide what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        inputs = {**kwargs, **{\"intermediate_steps\": intermediate_steps}}\\n        final_output: Any = None\\n        # Use streaming to make sure that the underlying LLM is invoked in a streaming\\n        # fashion to make it possible to get access to the individual LLM tokens\\n        # when using stream_log with the Agent Executor.\\n        # Because the response from the plan is not a generator, we need to\\n        # accumulate the output into final output and return that.\\n        async for chunk in self.runnable.astream(\\n            inputs, config={\"callbacks\": callbacks}\\n        ):\\n            if final_output is None:\\n                final_output = chunk\\n            else:\\n                final_output += chunk\\n        return final_output\\n\\n\\nclass RunnableMultiActionAgent(BaseMultiActionAgent):\\n    \"\"\"Agent powered by runnables.\"\"\"\\n\\n    runnable: Runnable[dict, Union[List[AgentAction], AgentFinish]]\\n    \"\"\"Runnable to call to get agent actions.\"\"\"\\n    input_keys_arg: List[str] = []\\n    return_keys_arg: List[str] = []\\n\\n    class Config:\\n        \"\"\"Configuration for this pydantic object.\"\"\"\\n\\n        arbitrary_types_allowed = True\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        \"\"\"Return values of the agent.\"\"\"\\n        return self.return_keys_arg\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        Returns:\\n            List of input keys.\\n        \"\"\"\\n        return self.input_keys_arg\\n\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[\\n        List[AgentAction],\\n        AgentFinish,\\n    ]:\\n        \"\"\"Based on past history and current inputs, decide what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        inputs = {**kwargs, **{\"intermediate_steps\": intermediate_steps}}\\n        # Use streaming to make sure that the underlying LLM is invoked in a streaming\\n        # fashion to make it possible to get access to the individual LLM tokens\\n        # when using stream_log with the Agent Executor.\\n        # Because the response from the plan is not a generator, we need to\\n        # accumulate the output into final output and return that.\\n        final_output: Any = None\\n        for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}):\\n            if final_output is None:\\n                final_output = chunk\\n            else:\\n                final_output += chunk\\n\\n        return final_output\\n\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[\\n        List[AgentAction],\\n        AgentFinish,\\n    ]:\\n        \"\"\"Based on past history and current inputs, decide what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        inputs = {**kwargs, **{\"intermediate_steps\": intermediate_steps}}\\n        # Use streaming to make sure that the underlying LLM is invoked in a streaming\\n        # fashion to make it possible to get access to the individual LLM tokens\\n        # when using stream_log with the Agent Executor.\\n        # Because the response from the plan is not a generator, we need to\\n        # accumulate the output into final output and return that.\\n        final_output: Any = None\\n        async for chunk in self.runnable.astream(\\n            inputs, config={\"callbacks\": callbacks}\\n        ):\\n            if final_output is None:\\n                final_output = chunk\\n            else:\\n                final_output += chunk\\n\\n        return final_output\\n\\n\\n@deprecated(\\n    \"0.1.0\",\\n    alternative=(\\n        \"Use new agent constructor methods like create_react_agent, create_json_agent, \"\\n        \"create_structured_chat_agent, etc.\"\\n    ),\\n    removal=\"0.2.0\",\\n)\\nclass LLMSingleActionAgent(BaseSingleActionAgent):\\n    \"\"\"Base class for single action agents.\"\"\"\\n\\n    llm_chain: LLMChain\\n    \"\"\"LLMChain to use for agent.\"\"\"\\n    output_parser: AgentOutputParser\\n    \"\"\"Output parser to use for agent.\"\"\"\\n    stop: List[str]\\n    \"\"\"List of strings to stop on.\"\"\"\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        Returns:\\n            List of input keys.\\n        \"\"\"\\n        return list(set(self.llm_chain.input_keys) - {\"intermediate_steps\"})\\n\\n    def dict(self, **kwargs: Any) -> Dict:\\n        \"\"\"Return dictionary representation of agent.\"\"\"\\n        _dict = super().dict()\\n        del _dict[\"output_parser\"]\\n        return _dict\\n\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        output = self.llm_chain.run(\\n            intermediate_steps=intermediate_steps,\\n            stop=self.stop,\\n            callbacks=callbacks,\\n            **kwargs,\\n        )\\n        return self.output_parser.parse(output)\\n\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        output = await self.llm_chain.arun(\\n            intermediate_steps=intermediate_steps,\\n            stop=self.stop,\\n            callbacks=callbacks,\\n            **kwargs,\\n        )\\n        return self.output_parser.parse(output)\\n\\n    def tool_run_logging_kwargs(self) -> Dict:\\n        return {\\n            \"llm_prefix\": \"\",\\n            \"observation_prefix\": \"\" if len(self.stop) == 0 else self.stop[0],\\n        }\\n\\n\\n@deprecated(\\n    \"0.1.0\",\\n    alternative=(\\n        \"Use new agent constructor methods like create_react_agent, create_json_agent, \"\\n        \"create_structured_chat_agent, etc.\"\\n    ),\\n    removal=\"0.2.0\",\\n)\\nclass Agent(BaseSingleActionAgent):\\n    \"\"\"Agent that calls the language model and deciding the action.\\n\\n    This is driven by an LLMChain. The prompt in the LLMChain MUST include\\n    a variable called \"agent_scratchpad\" where the agent can put its\\n    intermediary work.\\n    \"\"\"\\n\\n    llm_chain: LLMChain\\n    output_parser: AgentOutputParser\\n    allowed_tools: Optional[List[str]] = None\\n\\n    def dict(self, **kwargs: Any) -> Dict:\\n        \"\"\"Return dictionary representation of agent.\"\"\"\\n        _dict = super().dict()\\n        del _dict[\"output_parser\"]\\n        return _dict\\n\\n    def get_allowed_tools(self) -> Optional[List[str]]:\\n        return self.allowed_tools\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        return [\"output\"]\\n\\n    def _fix_text(self, text: str) -> str:\\n        \"\"\"Fix the text.\"\"\"\\n        raise ValueError(\"fix_text not implemented for this agent.\")\\n\\n    @property\\n    def _stop(self) -> List[str]:\\n        return [\\n            f\"\\\\n{self.observation_prefix.rstrip()}\",\\n            f\"\\\\n\\\\t{self.observation_prefix.rstrip()}\",\\n        ]\\n\\n    def _construct_scratchpad(\\n        self, intermediate_steps: List[Tuple[AgentAction, str]]\\n    ) -> Union[str, List[BaseMessage]]:\\n        \"\"\"Construct the scratchpad that lets the agent continue its thought process.\"\"\"\\n        thoughts = \"\"\\n        for action, observation in intermediate_steps:\\n            thoughts += action.log\\n            thoughts += f\"\\\\n{self.observation_prefix}{observation}\\\\n{self.llm_prefix}\"\\n        return thoughts\\n\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        full_inputs = self.get_full_inputs(intermediate_steps, **kwargs)\\n        full_output = self.llm_chain.predict(callbacks=callbacks, **full_inputs)\\n        return self.output_parser.parse(full_output)\\n\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        full_inputs = self.get_full_inputs(intermediate_steps, **kwargs)\\n        full_output = await self.llm_chain.apredict(callbacks=callbacks, **full_inputs)\\n        agent_output = await self.output_parser.aparse(full_output)\\n        return agent_output\\n\\n    def get_full_inputs(\\n        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\\n    ) -> Dict[str, Any]:\\n        \"\"\"Create the full inputs for the LLMChain from intermediate steps.\"\"\"\\n        thoughts = self._construct_scratchpad(intermediate_steps)\\n        new_inputs = {\"agent_scratchpad\": thoughts, \"stop\": self._stop}\\n        full_inputs = {**kwargs, **new_inputs}\\n        return full_inputs\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        :meta private:\\n        \"\"\"\\n        return list(set(self.llm_chain.input_keys) - {\"agent_scratchpad\"})\\n\\n    @root_validator()\\n    def validate_prompt(cls, values: Dict) -> Dict:\\n        \"\"\"Validate that prompt matches format.\"\"\"\\n        prompt = values[\"llm_chain\"].prompt\\n        if \"agent_scratchpad\" not in prompt.input_variables:\\n            logger.warning(\\n                \"`agent_scratchpad` should be a variable in prompt.input_variables.\"\\n                \" Did not find it, so adding it at the end.\"\\n            )\\n            prompt.input_variables.append(\"agent_scratchpad\")\\n            if isinstance(prompt, PromptTemplate):\\n                prompt.template += \"\\\\n{agent_scratchpad}\"\\n            elif isinstance(prompt, FewShotPromptTemplate):\\n                prompt.suffix += \"\\\\n{agent_scratchpad}\"\\n            else:\\n                raise ValueError(f\"Got unexpected prompt type {type(prompt)}\")\\n        return values\\n\\n    @property\\n    @abstractmethod\\n    def observation_prefix(self) -> str:\\n        \"\"\"Prefix to append the observation with.\"\"\"\\n\\n    @property\\n    @abstractmethod\\n    def llm_prefix(self) -> str:\\n        \"\"\"Prefix to append the LLM call with.\"\"\"\\n\\n    @classmethod\\n    @abstractmethod\\n    def create_prompt(cls, tools: Sequence[BaseTool]) -> BasePromptTemplate:\\n        \"\"\"Create a prompt for this class.\"\"\"\\n\\n    @classmethod\\n    def _validate_tools(cls, tools: Sequence[BaseTool]) -> None:\\n        \"\"\"Validate that appropriate tools are passed in.\"\"\"\\n        pass\\n\\n    @classmethod\\n    @abstractmethod\\n    def _get_default_output_parser(cls, **kwargs: Any) -> AgentOutputParser:\\n        \"\"\"Get default output parser for this class.\"\"\"\\n\\n    @classmethod\\n    def from_llm_and_tools(\\n        cls,\\n        llm: BaseLanguageModel,\\n        tools: Sequence[BaseTool],\\n        callback_manager: Optional[BaseCallbackManager] = None,\\n        output_parser: Optional[AgentOutputParser] = None,\\n        **kwargs: Any,\\n    ) -> Agent:\\n        \"\"\"Construct an agent from an LLM and tools.\"\"\"\\n        cls._validate_tools(tools)\\n        llm_chain = LLMChain(\\n            llm=llm,\\n            prompt=cls.create_prompt(tools),\\n            callback_manager=callback_manager,\\n        )\\n        tool_names = [tool.name for tool in tools]\\n        _output_parser = output_parser or cls._get_default_output_parser()\\n        return cls(\\n            llm_chain=llm_chain,\\n            allowed_tools=tool_names,\\n            output_parser=_output_parser,\\n            **kwargs,\\n        )\\n\\n    def return_stopped_response(\\n        self,\\n        early_stopping_method: str,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        **kwargs: Any,\\n    ) -> AgentFinish:\\n        \"\"\"Return response when agent has been stopped due to max iterations.\"\"\"\\n        if early_stopping_method == \"force\":\\n            # `force` just returns a constant string\\n            return AgentFinish(\\n                {\"output\": \"Agent stopped due to iteration limit or time limit.\"}, \"\"\\n            )\\n        elif early_stopping_method == \"generate\":\\n            # Generate does one final forward pass\\n            thoughts = \"\"\\n            for action, observation in intermediate_steps:\\n                thoughts += action.log\\n                thoughts += (\\n                    f\"\\\\n{self.observation_prefix}{observation}\\\\n{self.llm_prefix}\"\\n                )\\n            # Adding to the previous steps, we now tell the LLM to make a final pred\\n            thoughts += (\\n                \"\\\\n\\\\nI now need to return a final answer based on the previous steps:\"\\n            )\\n            new_inputs = {\"agent_scratchpad\": thoughts, \"stop\": self._stop}\\n            full_inputs = {**kwargs, **new_inputs}\\n            full_output = self.llm_chain.predict(**full_inputs)\\n            # We try to extract a final answer\\n            parsed_output = self.output_parser.parse(full_output)\\n            if isinstance(parsed_output, AgentFinish):\\n                # If we can extract, we send the correct stuff\\n                return parsed_output\\n            else:\\n                # If we can extract, but the tool is not the final tool,\\n                # we just return the full output\\n                return AgentFinish({\"output\": full_output}, full_output)\\n        else:\\n            raise ValueError(\\n                \"early_stopping_method should be one of `force` or `generate`, \"\\n                f\"got {early_stopping_method}\"\\n            )\\n\\n    def tool_run_logging_kwargs(self) -> Dict:\\n        return {\\n            \"llm_prefix\": self.llm_prefix,\\n            \"observation_prefix\": self.observation_prefix,\\n        }\\n\\n\\nclass ExceptionTool(BaseTool):\\n    \"\"\"Tool that just returns the query.\"\"\"\\n\\n    name: str = \"_Exception\"\\n    \"\"\"Name of the tool.\"\"\"\\n    description: str = \"Exception tool\"\\n    \"\"\"Description of the tool.\"\"\"\\n\\n    def _run(\\n        self,\\n        query: str,\\n        run_manager: Optional[CallbackManagerForToolRun] = None,\\n    ) -> str:\\n        return query\\n\\n    async def _arun(\\n        self,\\n        query: str,\\n        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\\n    ) -> str:\\n        return query\\n\\n\\nNextStepOutput = List[Union[AgentFinish, AgentAction, AgentStep]]\\n\\n\\nclass AgentExecutor(Chain):\\n    \"\"\"Agent that is using tools.\"\"\"\\n\\n    agent: Union[BaseSingleActionAgent, BaseMultiActionAgent]\\n    \"\"\"The agent to run for creating a plan and determining actions\\n    to take at each step of the execution loop.\"\"\"\\n    tools: Sequence[BaseTool]\\n    \"\"\"The valid tools the agent can call.\"\"\"\\n    return_intermediate_steps: bool = False\\n    \"\"\"Whether to return the agent\\'s trajectory of intermediate steps\\n    at the end in addition to the final output.\"\"\"\\n    max_iterations: Optional[int] = 15\\n    \"\"\"The maximum number of steps to take before ending the execution\\n    loop.\\n    \\n    Setting to \\'None\\' could lead to an infinite loop.\"\"\"\\n    max_execution_time: Optional[float] = None\\n    \"\"\"The maximum amount of wall clock time to spend in the execution\\n    loop.\\n    \"\"\"\\n    early_stopping_method: str = \"force\"\\n    \"\"\"The method to use for early stopping if the agent never\\n    returns `AgentFinish`. Either \\'force\\' or \\'generate\\'.\\n\\n    `\"force\"` returns a string saying that it stopped because it met a\\n        time or iteration limit.\\n    \\n    `\"generate\"` calls the agent\\'s LLM Chain one final time to generate\\n        a final answer based on the previous steps.\\n    \"\"\"\\n    handle_parsing_errors: Union[\\n        bool, str, Callable[[OutputParserException], str]\\n    ] = False\\n    \"\"\"How to handle errors raised by the agent\\'s output parser.\\n    Defaults to `False`, which raises the error.\\n    If `true`, the error will be sent back to the LLM as an observation.\\n    If a string, the string itself will be sent to the LLM as an observation.\\n    If a callable function, the function will be called with the exception\\n     as an argument, and the result of that function will be passed to the agent\\n      as an observation.\\n    \"\"\"\\n    trim_intermediate_steps: Union[\\n        int, Callable[[List[Tuple[AgentAction, str]]], List[Tuple[AgentAction, str]]]\\n    ] = -1\\n\\n    @classmethod\\n    def from_agent_and_tools(\\n        cls,\\n        agent: Union[BaseSingleActionAgent, BaseMultiActionAgent],\\n        tools: Sequence[BaseTool],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> AgentExecutor:\\n        \"\"\"Create from agent and tools.\"\"\"\\n        return cls(\\n            agent=agent,\\n            tools=tools,\\n            callbacks=callbacks,\\n            **kwargs,\\n        )\\n\\n    @root_validator()\\n    def validate_tools(cls, values: Dict) -> Dict:\\n        \"\"\"Validate that tools are compatible with agent.\"\"\"\\n        agent = values[\"agent\"]\\n        tools = values[\"tools\"]\\n        allowed_tools = agent.get_allowed_tools()\\n        if allowed_tools is not None:\\n            if set(allowed_tools) != set([tool.name for tool in tools]):\\n                raise ValueError(\\n                    f\"Allowed tools ({allowed_tools}) different than \"\\n                    f\"provided tools ({[tool.name for tool in tools]})\"\\n                )\\n        return values\\n\\n    @root_validator()\\n    def validate_return_direct_tool(cls, values: Dict) -> Dict:\\n        \"\"\"Validate that tools are compatible with agent.\"\"\"\\n        agent = values[\"agent\"]\\n        tools = values[\"tools\"]\\n        if isinstance(agent, BaseMultiActionAgent):\\n            for tool in tools:\\n                if tool.return_direct:\\n                    raise ValueError(\\n                        \"Tools that have `return_direct=True` are not allowed \"\\n                        \"in multi-action agents\"\\n                    )\\n        return values\\n\\n    @root_validator(pre=True)\\n    def validate_runnable_agent(cls, values: Dict) -> Dict:\\n        \"\"\"Convert runnable to agent if passed in.\"\"\"\\n        agent = values[\"agent\"]\\n        if isinstance(agent, Runnable):\\n            try:\\n                output_type = agent.OutputType\\n            except Exception as _:\\n                multi_action = False\\n            else:\\n                multi_action = output_type == Union[List[AgentAction], AgentFinish]\\n\\n            if multi_action:\\n                values[\"agent\"] = RunnableMultiActionAgent(runnable=agent)\\n            else:\\n                values[\"agent\"] = RunnableAgent(runnable=agent)\\n        return values\\n\\n    def save(self, file_path: Union[Path, str]) -> None:\\n        \"\"\"Raise error - saving not supported for Agent Executors.\"\"\"\\n        raise ValueError(\\n            \"Saving not supported for agent executors. \"\\n            \"If you are trying to save the agent, please use the \"\\n            \"`.save_agent(...)`\"\\n        )\\n\\n    def save_agent(self, file_path: Union[Path, str]) -> None:\\n        \"\"\"Save the underlying agent.\"\"\"\\n        return self.agent.save(file_path)\\n\\n    def iter(\\n        self,\\n        inputs: Any,\\n        callbacks: Callbacks = None,\\n        *,\\n        include_run_info: bool = False,\\n        async_: bool = False,  # arg kept for backwards compat, but ignored\\n    ) -> AgentExecutorIterator:\\n        \"\"\"Enables iteration over steps taken to reach final output.\"\"\"\\n        return AgentExecutorIterator(\\n            self,\\n            inputs,\\n            callbacks,\\n            tags=self.tags,\\n            include_run_info=include_run_info,\\n        )\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        :meta private:\\n        \"\"\"\\n        return self.agent.input_keys\\n\\n    @property\\n    def output_keys(self) -> List[str]:\\n        \"\"\"Return the singular output key.\\n\\n        :meta private:\\n        \"\"\"\\n        if self.return_intermediate_steps:\\n            return self.agent.return_values + [\"intermediate_steps\"]\\n        else:\\n            return self.agent.return_values\\n\\n    def lookup_tool(self, name: str) -> BaseTool:\\n        \"\"\"Lookup tool by name.\"\"\"\\n        return {tool.name: tool for tool in self.tools}[name]\\n\\n    def _should_continue(self, iterations: int, time_elapsed: float) -> bool:\\n        if self.max_iterations is not None and iterations >= self.max_iterations:\\n            return False\\n        if (\\n            self.max_execution_time is not None\\n            and time_elapsed >= self.max_execution_time\\n        ):\\n            return False\\n\\n        return True\\n\\n    def _return(\\n        self,\\n        output: AgentFinish,\\n        intermediate_steps: list,\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> Dict[str, Any]:\\n        if run_manager:\\n            run_manager.on_agent_finish(output, color=\"green\", verbose=self.verbose)\\n        final_output = output.return_values\\n        if self.return_intermediate_steps:\\n            final_output[\"intermediate_steps\"] = intermediate_steps\\n        return final_output\\n\\n    async def _areturn(\\n        self,\\n        output: AgentFinish,\\n        intermediate_steps: list,\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> Dict[str, Any]:\\n        if run_manager:\\n            await run_manager.on_agent_finish(\\n                output, color=\"green\", verbose=self.verbose\\n            )\\n        final_output = output.return_values\\n        if self.return_intermediate_steps:\\n            final_output[\"intermediate_steps\"] = intermediate_steps\\n        return final_output\\n\\n    def _consume_next_step(\\n        self, values: NextStepOutput\\n    ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\\n        if isinstance(values[-1], AgentFinish):\\n            assert len(values) == 1\\n            return values[-1]\\n        else:\\n            return [\\n                (a.action, a.observation) for a in values if isinstance(a, AgentStep)\\n            ]\\n\\n    def _take_next_step(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        inputs: Dict[str, str],\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\\n        return self._consume_next_step(\\n            [\\n                a\\n                for a in self._iter_next_step(\\n                    name_to_tool_map,\\n                    color_mapping,\\n                    inputs,\\n                    intermediate_steps,\\n                    run_manager,\\n                )\\n            ]\\n        )\\n\\n    def _iter_next_step(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        inputs: Dict[str, str],\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> Iterator[Union[AgentFinish, AgentAction, AgentStep]]:\\n        \"\"\"Take a single step in the thought-action-observation loop.\\n\\n        Override this to take control of how the agent makes and acts on choices.\\n        \"\"\"\\n        try:\\n            intermediate_steps = self._prepare_intermediate_steps(intermediate_steps)\\n\\n            # Call the LLM to see what to do.\\n            output = self.agent.plan(\\n                intermediate_steps,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **inputs,\\n            )\\n        except OutputParserException as e:\\n            if isinstance(self.handle_parsing_errors, bool):\\n                raise_error = not self.handle_parsing_errors\\n            else:\\n                raise_error = False\\n            if raise_error:\\n                raise ValueError(\\n                    \"An output parsing error occurred. \"\\n                    \"In order to pass this error back to the agent and have it try \"\\n                    \"again, pass `handle_parsing_errors=True` to the AgentExecutor. \"\\n                    f\"This is the error: {str(e)}\"\\n                )\\n            text = str(e)\\n            if isinstance(self.handle_parsing_errors, bool):\\n                if e.send_to_llm:\\n                    observation = str(e.observation)\\n                    text = str(e.llm_output)\\n                else:\\n                    observation = \"Invalid or incomplete response\"\\n            elif isinstance(self.handle_parsing_errors, str):\\n                observation = self.handle_parsing_errors\\n            elif callable(self.handle_parsing_errors):\\n                observation = self.handle_parsing_errors(e)\\n            else:\\n                raise ValueError(\"Got unexpected type of `handle_parsing_errors`\")\\n            output = AgentAction(\"_Exception\", observation, text)\\n            if run_manager:\\n                run_manager.on_agent_action(output, color=\"green\")\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            observation = ExceptionTool().run(\\n                output.tool_input,\\n                verbose=self.verbose,\\n                color=None,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n            yield AgentStep(action=output, observation=observation)\\n            return\\n\\n        # If the tool chosen is the finishing tool, then we end and return.\\n        if isinstance(output, AgentFinish):\\n            yield output\\n            return\\n\\n        actions: List[AgentAction]\\n        if isinstance(output, AgentAction):\\n            actions = [output]\\n        else:\\n            actions = output\\n        for agent_action in actions:\\n            yield agent_action\\n        for agent_action in actions:\\n            yield self._perform_agent_action(\\n                name_to_tool_map, color_mapping, agent_action, run_manager\\n            )\\n\\n    def _perform_agent_action(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        agent_action: AgentAction,\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> AgentStep:\\n        if run_manager:\\n            run_manager.on_agent_action(agent_action, color=\"green\")\\n        # Otherwise we lookup the tool\\n        if agent_action.tool in name_to_tool_map:\\n            tool = name_to_tool_map[agent_action.tool]\\n            return_direct = tool.return_direct\\n            color = color_mapping[agent_action.tool]\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            if return_direct:\\n                tool_run_kwargs[\"llm_prefix\"] = \"\"\\n            # We then call the tool on the tool input to get an observation\\n            observation = tool.run(\\n                agent_action.tool_input,\\n                verbose=self.verbose,\\n                color=color,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n        else:\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            observation = InvalidTool().run(\\n                {\\n                    \"requested_tool_name\": agent_action.tool,\\n                    \"available_tool_names\": list(name_to_tool_map.keys()),\\n                },\\n                verbose=self.verbose,\\n                color=None,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n        return AgentStep(action=agent_action, observation=observation)\\n\\n    async def _atake_next_step(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        inputs: Dict[str, str],\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\\n        return self._consume_next_step(\\n            [\\n                a\\n                async for a in self._aiter_next_step(\\n                    name_to_tool_map,\\n                    color_mapping,\\n                    inputs,\\n                    intermediate_steps,\\n                    run_manager,\\n                )\\n            ]\\n        )\\n\\n    async def _aiter_next_step(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        inputs: Dict[str, str],\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> AsyncIterator[Union[AgentFinish, AgentAction, AgentStep]]:\\n        \"\"\"Take a single step in the thought-action-observation loop.\\n\\n        Override this to take control of how the agent makes and acts on choices.\\n        \"\"\"\\n        try:\\n            intermediate_steps = self._prepare_intermediate_steps(intermediate_steps)\\n\\n            # Call the LLM to see what to do.\\n            output = await self.agent.aplan(\\n                intermediate_steps,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **inputs,\\n            )\\n        except OutputParserException as e:\\n            if isinstance(self.handle_parsing_errors, bool):\\n                raise_error = not self.handle_parsing_errors\\n            else:\\n                raise_error = False\\n            if raise_error:\\n                raise ValueError(\\n                    \"An output parsing error occurred. \"\\n                    \"In order to pass this error back to the agent and have it try \"\\n                    \"again, pass `handle_parsing_errors=True` to the AgentExecutor. \"\\n                    f\"This is the error: {str(e)}\"\\n                )\\n            text = str(e)\\n            if isinstance(self.handle_parsing_errors, bool):\\n                if e.send_to_llm:\\n                    observation = str(e.observation)\\n                    text = str(e.llm_output)\\n                else:\\n                    observation = \"Invalid or incomplete response\"\\n            elif isinstance(self.handle_parsing_errors, str):\\n                observation = self.handle_parsing_errors\\n            elif callable(self.handle_parsing_errors):\\n                observation = self.handle_parsing_errors(e)\\n            else:\\n                raise ValueError(\"Got unexpected type of `handle_parsing_errors`\")\\n            output = AgentAction(\"_Exception\", observation, text)\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            observation = await ExceptionTool().arun(\\n                output.tool_input,\\n                verbose=self.verbose,\\n                color=None,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n            yield AgentStep(action=output, observation=observation)\\n            return\\n\\n        # If the tool chosen is the finishing tool, then we end and return.\\n        if isinstance(output, AgentFinish):\\n            yield output\\n            return\\n\\n        actions: List[AgentAction]\\n        if isinstance(output, AgentAction):\\n            actions = [output]\\n        else:\\n            actions = output\\n        for agent_action in actions:\\n            yield agent_action\\n\\n        # Use asyncio.gather to run multiple tool.arun() calls concurrently\\n        result = await asyncio.gather(\\n            *[\\n                self._aperform_agent_action(\\n                    name_to_tool_map, color_mapping, agent_action, run_manager\\n                )\\n                for agent_action in actions\\n            ],\\n        )\\n\\n        # TODO This could yield each result as it becomes available\\n        for chunk in result:\\n            yield chunk\\n\\n    async def _aperform_agent_action(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        agent_action: AgentAction,\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> AgentStep:\\n        if run_manager:\\n            await run_manager.on_agent_action(\\n                agent_action, verbose=self.verbose, color=\"green\"\\n            )\\n        # Otherwise we lookup the tool\\n        if agent_action.tool in name_to_tool_map:\\n            tool = name_to_tool_map[agent_action.tool]\\n            return_direct = tool.return_direct\\n            color = color_mapping[agent_action.tool]\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            if return_direct:\\n                tool_run_kwargs[\"llm_prefix\"] = \"\"\\n            # We then call the tool on the tool input to get an observation\\n            observation = await tool.arun(\\n                agent_action.tool_input,\\n                verbose=self.verbose,\\n                color=color,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n        else:\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            observation = await InvalidTool().arun(\\n                {\\n                    \"requested_tool_name\": agent_action.tool,\\n                    \"available_tool_names\": list(name_to_tool_map.keys()),\\n                },\\n                verbose=self.verbose,\\n                color=None,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n        return AgentStep(action=agent_action, observation=observation)\\n\\n    def _call(\\n        self,\\n        inputs: Dict[str, str],\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> Dict[str, Any]:\\n        \"\"\"Run text through and get agent response.\"\"\"\\n        # Construct a mapping of tool name to tool for easy lookup\\n        name_to_tool_map = {tool.name: tool for tool in self.tools}\\n        # We construct a mapping from each tool to a color, used for logging.\\n        color_mapping = get_color_mapping(\\n            [tool.name for tool in self.tools], excluded_colors=[\"green\", \"red\"]\\n        )\\n        intermediate_steps: List[Tuple[AgentAction, str]] = []\\n        # Let\\'s start tracking the number of iterations and time elapsed\\n        iterations = 0\\n        time_elapsed = 0.0\\n        start_time = time.time()\\n        # We now enter the agent loop (until it returns something).\\n        while self._should_continue(iterations, time_elapsed):\\n            next_step_output = self._take_next_step(\\n                name_to_tool_map,\\n                color_mapping,\\n                inputs,\\n                intermediate_steps,\\n                run_manager=run_manager,\\n            )\\n            if isinstance(next_step_output, AgentFinish):\\n                return self._return(\\n                    next_step_output, intermediate_steps, run_manager=run_manager\\n                )\\n\\n            intermediate_steps.extend(next_step_output)\\n            if len(next_step_output) == 1:\\n                next_step_action = next_step_output[0]\\n                # See if tool should return directly\\n                tool_return = self._get_tool_return(next_step_action)\\n                if tool_return is not None:\\n                    return self._return(\\n                        tool_return, intermediate_steps, run_manager=run_manager\\n                    )\\n            iterations += 1\\n            time_elapsed = time.time() - start_time\\n        output = self.agent.return_stopped_response(\\n            self.early_stopping_method, intermediate_steps, **inputs\\n        )\\n        return self._return(output, intermediate_steps, run_manager=run_manager)\\n\\n    async def _acall(\\n        self,\\n        inputs: Dict[str, str],\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> Dict[str, str]:\\n        \"\"\"Run text through and get agent response.\"\"\"\\n        # Construct a mapping of tool name to tool for easy lookup\\n        name_to_tool_map = {tool.name: tool for tool in self.tools}\\n        # We construct a mapping from each tool to a color, used for logging.\\n        color_mapping = get_color_mapping(\\n            [tool.name for tool in self.tools], excluded_colors=[\"green\"]\\n        )\\n        intermediate_steps: List[Tuple[AgentAction, str]] = []\\n        # Let\\'s start tracking the number of iterations and time elapsed\\n        iterations = 0\\n        time_elapsed = 0.0\\n        start_time = time.time()\\n        # We now enter the agent loop (until it returns something).\\n        try:\\n            async with asyncio_timeout(self.max_execution_time):\\n                while self._should_continue(iterations, time_elapsed):\\n                    next_step_output = await self._atake_next_step(\\n                        name_to_tool_map,\\n                        color_mapping,\\n                        inputs,\\n                        intermediate_steps,\\n                        run_manager=run_manager,\\n                    )\\n                    if isinstance(next_step_output, AgentFinish):\\n                        return await self._areturn(\\n                            next_step_output,\\n                            intermediate_steps,\\n                            run_manager=run_manager,\\n                        )\\n\\n                    intermediate_steps.extend(next_step_output)\\n                    if len(next_step_output) == 1:\\n                        next_step_action = next_step_output[0]\\n                        # See if tool should return directly\\n                        tool_return = self._get_tool_return(next_step_action)\\n                        if tool_return is not None:\\n                            return await self._areturn(\\n                                tool_return, intermediate_steps, run_manager=run_manager\\n                            )\\n\\n                    iterations += 1\\n                    time_elapsed = time.time() - start_time\\n                output = self.agent.return_stopped_response(\\n                    self.early_stopping_method, intermediate_steps, **inputs\\n                )\\n                return await self._areturn(\\n                    output, intermediate_steps, run_manager=run_manager\\n                )\\n        except (TimeoutError, asyncio.TimeoutError):\\n            # stop early when interrupted by the async timeout\\n            output = self.agent.return_stopped_response(\\n                self.early_stopping_method, intermediate_steps, **inputs\\n            )\\n            return await self._areturn(\\n                output, intermediate_steps, run_manager=run_manager\\n            )\\n\\n    def _get_tool_return(\\n        self, next_step_output: Tuple[AgentAction, str]\\n    ) -> Optional[AgentFinish]:\\n        \"\"\"Check if the tool is a returning tool.\"\"\"\\n        agent_action, observation = next_step_output\\n        name_to_tool_map = {tool.name: tool for tool in self.tools}\\n        return_value_key = \"output\"\\n        if len(self.agent.return_values) > 0:\\n            return_value_key = self.agent.return_values[0]\\n        # Invalid tools won\\'t be in the map, so we return False.\\n        if agent_action.tool in name_to_tool_map:\\n            if name_to_tool_map[agent_action.tool].return_direct:\\n                return AgentFinish(\\n                    {return_value_key: observation},\\n                    \"\",\\n                )\\n        return None\\n\\n    def _prepare_intermediate_steps(\\n        self, intermediate_steps: List[Tuple[AgentAction, str]]\\n    ) -> List[Tuple[AgentAction, str]]:\\n        if (\\n            isinstance(self.trim_intermediate_steps, int)\\n            and self.trim_intermediate_steps > 0\\n        ):\\n            return intermediate_steps[-self.trim_intermediate_steps :]\\n        elif callable(self.trim_intermediate_steps):\\n            return self.trim_intermediate_steps(intermediate_steps)\\n        else:\\n            return intermediate_steps\\n\\n    def stream(\\n        self,\\n        input: Union[Dict[str, Any], Any],\\n        config: Optional[RunnableConfig] = None,\\n        **kwargs: Any,\\n    ) -> Iterator[AddableDict]:\\n        \"\"\"Enables streaming over steps taken to reach final output.\"\"\"\\n        config = ensure_config(config)\\n        iterator = AgentExecutorIterator(\\n            self,\\n            input,\\n            config.get(\"callbacks\"),\\n            tags=config.get(\"tags\"),\\n            metadata=config.get(\"metadata\"),\\n            run_name=config.get(\"run_name\"),\\n            yield_actions=True,\\n            **kwargs,\\n        )\\n        for step in iterator:\\n            yield step\\n\\n    async def astream(\\n        self,\\n        input: Union[Dict[str, Any], Any],\\n        config: Optional[RunnableConfig] = None,\\n        **kwargs: Any,\\n    ) -> AsyncIterator[AddableDict]:\\n        \"\"\"Enables streaming over steps taken to reach final output.\"\"\"\\n        config = ensure_config(config)\\n        iterator = AgentExecutorIterator(\\n            self,\\n            input,\\n            config.get(\"callbacks\"),\\n            tags=config.get(\"tags\"),\\n            metadata=config.get(\"metadata\"),\\n            run_name=config.get(\"run_name\"),\\n            yield_actions=True,\\n            **kwargs,\\n        )\\n        async for step in iterator:\\n            yield step\\n',\n",
       " 'output': ['Config',\n",
       "  'LLMSingleActionAgent',\n",
       "  'BaseMultiActionAgent',\n",
       "  'RunnableMultiActionAgent',\n",
       "  'MultiActionAgentOutputParser',\n",
       "  'Agent',\n",
       "  'BaseSingleActionAgent',\n",
       "  'AgentOutputParser',\n",
       "  'ExceptionTool',\n",
       "  'AgentExecutor',\n",
       "  'RunnableAgent'],\n",
       " 'metadata': {'file_path': 'langchain-master/libs/langchain/langchain/agents/agent.py',\n",
       "  'file_length': 14571,\n",
       "  'symbol_dict': [{'symbol': 'Agent',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 19563,\n",
       "    'location': 5309},\n",
       "   {'symbol': 'MultiActionAgentOutputParser',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 9940,\n",
       "    'location': 2764},\n",
       "   {'symbol': 'Config',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 10529,\n",
       "    'location': 2939},\n",
       "   {'symbol': 'BaseSingleActionAgent',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 1758,\n",
       "    'location': 490},\n",
       "   {'symbol': 'BaseMultiActionAgent',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 5929,\n",
       "    'location': 1648},\n",
       "   {'symbol': 'AgentExecutor',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 28269,\n",
       "    'location': 7706},\n",
       "   {'symbol': 'AgentOutputParser',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 9651,\n",
       "    'location': 2685},\n",
       "   {'symbol': 'RunnableAgent',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 10260,\n",
       "    'location': 2852},\n",
       "   {'symbol': 'LLMSingleActionAgent',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 16964,\n",
       "    'location': 4579},\n",
       "   {'symbol': 'ExceptionTool',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 27681,\n",
       "    'location': 7535},\n",
       "   {'symbol': 'RunnableMultiActionAgent',\n",
       "    'type': 'mannual_defined_class',\n",
       "    'byte_location': 13433,\n",
       "    'location': 3660}]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocomplete import extract_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_code = lines[0]['input']\n",
    "extracted = extract_symbols(inp_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_symbol_suggestion(suggestions):\n",
    "    imports = suggestions['imports'] + suggestions['imports_as'] + suggestions['imports_from']\n",
    "    relative_imports = suggestions['imports_relative']\n",
    "    global_vars = suggestions['global_vars']\n",
    "    functions = suggestions['functions']\n",
    "    classes = suggestions['class_def']\n",
    "\n",
    "    rtn = {'import_package_or_function': imports, \n",
    "            'relative_import': relative_imports,\n",
    "            'global_variable': global_vars,\n",
    "            'mannual_defined_function': functions,\n",
    "            'mannual_defined_class': classes}\n",
    "    rtn = {k:v for k,v in rtn.items() if len(v) > 0}\n",
    "    return \"\\n\".join([k + \": \" + \", \".join([e[0] for e in v]) for k,v in rtn.items()]), rtn\n",
    "def extract(each_content):\n",
    "    api_calls, suggestions = extract_symbols(each_content)\n",
    "    suggestions, suggestion_loc = format_symbol_suggestion(suggestions)\n",
    "    symbol_dict = {}\n",
    "    for k in suggestion_loc:\n",
    "        for e in suggestion_loc[k]:\n",
    "            symbol_dict[e[0]] = {\"type\": k, \"code\": e[1][0], \"pos\": e[1][1]}\n",
    "    rst = { \"symbols\": symbol_dict, \"content\": each_content}\n",
    "    return rst\n",
    "\n",
    "def codeContext2jsonContext(each_content):\n",
    "    api_calls, suggestions = extract_symbols(each_content)\n",
    "    suggestions, suggestion_loc = format_symbol_suggestion(suggestions)\n",
    "    symbol_dict = {}\n",
    "    for k in suggestion_loc:\n",
    "        if k not in ['mannual_defined_function', 'mannual_defined_class']:\n",
    "            continue\n",
    "        for e in suggestion_loc[k]:\n",
    "            symbol_dict[e[0]] = {\"type\": k, \"code_body\": e[1][0], \"pos\": e[1][1]}\n",
    "    # rst = { \"symbols\": symbol_dict, \"content\": each_content}\n",
    "    # json_context = [{\"entity_name\": \"\", \"entity_body\": \"\"}]\n",
    "    json_context = []\n",
    "    for k in suggestion_loc:\n",
    "        if k in ['mannual_defined_function', 'mannual_defined_class']:\n",
    "            for e in suggestion_loc[k]:\n",
    "                json_context.append({\"entity_name\": e[0], \"entity_body\": e[1][0]})\n",
    "    return json_context\n",
    "\n",
    "out = codeContext2jsonContext(inp_code)\n",
    "# out['symbols']\n",
    "# out['mannual_defined_class'][0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Config': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class Config:\\n        \"\"\"Configuration for this pydantic object.\"\"\"\\n\\n        arbitrary_types_allowed = True',\n",
       "  'pos': 13719},\n",
       " 'RunnableAgent': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class RunnableAgent(BaseSingleActionAgent):\\n    \"\"\"Agent powered by runnables.\"\"\"\\n\\n    runnable: Runnable[dict, Union[AgentAction, AgentFinish]]\\n    \"\"\"Runnable to call to get agent action.\"\"\"\\n    input_keys_arg: List[str] = []\\n    return_keys_arg: List[str] = []\\n\\n    class Config:\\n        \"\"\"Configuration for this pydantic object.\"\"\"\\n\\n        arbitrary_types_allowed = True\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        \"\"\"Return values of the agent.\"\"\"\\n        return self.return_keys_arg\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        return self.input_keys_arg\\n\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Based on past history and current inputs, decide what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        inputs = {**kwargs, **{\"intermediate_steps\": intermediate_steps}}\\n        # Use streaming to make sure that the underlying LLM is invoked in a streaming\\n        # fashion to make it possible to get access to the individual LLM tokens\\n        # when using stream_log with the Agent Executor.\\n        # Because the response from the plan is not a generator, we need to\\n        # accumulate the output into final output and return that.\\n        final_output: Any = None\\n        for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}):\\n            if final_output is None:\\n                final_output = chunk\\n            else:\\n                final_output += chunk\\n\\n        return final_output\\n\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[\\n        AgentAction,\\n        AgentFinish,\\n    ]:\\n        \"\"\"Based on past history and current inputs, decide what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        inputs = {**kwargs, **{\"intermediate_steps\": intermediate_steps}}\\n        final_output: Any = None\\n        # Use streaming to make sure that the underlying LLM is invoked in a streaming\\n        # fashion to make it possible to get access to the individual LLM tokens\\n        # when using stream_log with the Agent Executor.\\n        # Because the response from the plan is not a generator, we need to\\n        # accumulate the output into final output and return that.\\n        async for chunk in self.runnable.astream(\\n            inputs, config={\"callbacks\": callbacks}\\n        ):\\n            if final_output is None:\\n                final_output = chunk\\n            else:\\n                final_output += chunk\\n        return final_output',\n",
       "  'pos': 10260},\n",
       " 'ExceptionTool': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class ExceptionTool(BaseTool):\\n    \"\"\"Tool that just returns the query.\"\"\"\\n\\n    name: str = \"_Exception\"\\n    \"\"\"Name of the tool.\"\"\"\\n    description: str = \"Exception tool\"\\n    \"\"\"Description of the tool.\"\"\"\\n\\n    def _run(\\n        self,\\n        query: str,\\n        run_manager: Optional[CallbackManagerForToolRun] = None,\\n    ) -> str:\\n        return query\\n\\n    async def _arun(\\n        self,\\n        query: str,\\n        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\\n    ) -> str:\\n        return query',\n",
       "  'pos': 27681},\n",
       " 'BaseMultiActionAgent': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class BaseMultiActionAgent(BaseModel):\\n    \"\"\"Base Multi Action Agent class.\"\"\"\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        \"\"\"Return values of the agent.\"\"\"\\n        return [\"output\"]\\n\\n    def get_allowed_tools(self) -> Optional[List[str]]:\\n        return None\\n\\n    @abstractmethod\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[List[AgentAction], AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Actions specifying what tool to use.\\n        \"\"\"\\n\\n    @abstractmethod\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[List[AgentAction], AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Actions specifying what tool to use.\\n        \"\"\"\\n\\n    @property\\n    @abstractmethod\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        :meta private:\\n        \"\"\"\\n\\n    def return_stopped_response(\\n        self,\\n        early_stopping_method: str,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        **kwargs: Any,\\n    ) -> AgentFinish:\\n        \"\"\"Return response when agent has been stopped due to max iterations.\"\"\"\\n        if early_stopping_method == \"force\":\\n            # `force` just returns a constant string\\n            return AgentFinish({\"output\": \"Agent stopped due to max iterations.\"}, \"\")\\n        else:\\n            raise ValueError(\\n                f\"Got unsupported early_stopping_method `{early_stopping_method}`\"\\n            )\\n\\n    @property\\n    def _agent_type(self) -> str:\\n        \"\"\"Return Identifier of agent type.\"\"\"\\n        raise NotImplementedError\\n\\n    def dict(self, **kwargs: Any) -> Dict:\\n        \"\"\"Return dictionary representation of agent.\"\"\"\\n        _dict = super().dict()\\n        try:\\n            _dict[\"_type\"] = str(self._agent_type)\\n        except NotImplementedError:\\n            pass\\n        return _dict\\n\\n    def save(self, file_path: Union[Path, str]) -> None:\\n        \"\"\"Save the agent.\\n\\n        Args:\\n            file_path: Path to file to save the agent to.\\n\\n        Example:\\n        .. code-block:: python\\n\\n            # If working with agent executor\\n            agent.agent.save(file_path=\"path/agent.yaml\")\\n        \"\"\"\\n        # Convert file to Path object.\\n        if isinstance(file_path, str):\\n            save_path = Path(file_path)\\n        else:\\n            save_path = file_path\\n\\n        # Fetch dictionary to save\\n        agent_dict = self.dict()\\n        if \"_type\" not in agent_dict:\\n            raise NotImplementedError(f\"Agent {self} does not support saving.\")\\n\\n        directory_path = save_path.parent\\n        directory_path.mkdir(parents=True, exist_ok=True)\\n\\n        if save_path.suffix == \".json\":\\n            with open(file_path, \"w\") as f:\\n                json.dump(agent_dict, f, indent=4)\\n        elif save_path.suffix == \".yaml\":\\n            with open(file_path, \"w\") as f:\\n                yaml.dump(agent_dict, f, default_flow_style=False)\\n        else:\\n            raise ValueError(f\"{save_path} must be json or yaml\")\\n\\n    def tool_run_logging_kwargs(self) -> Dict:\\n        return {}',\n",
       "  'pos': 5929},\n",
       " 'AgentOutputParser': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class AgentOutputParser(BaseOutputParser[Union[AgentAction, AgentFinish]]):\\n    \"\"\"Base class for parsing agent output into agent action/finish.\"\"\"\\n\\n    @abstractmethod\\n    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Parse text into agent action/finish.\"\"\"',\n",
       "  'pos': 9651},\n",
       " 'BaseSingleActionAgent': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class BaseSingleActionAgent(BaseModel):\\n    \"\"\"Base Single Action Agent class.\"\"\"\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        \"\"\"Return values of the agent.\"\"\"\\n        return [\"output\"]\\n\\n    def get_allowed_tools(self) -> Optional[List[str]]:\\n        return None\\n\\n    @abstractmethod\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n\\n    @abstractmethod\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n\\n    @property\\n    @abstractmethod\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        :meta private:\\n        \"\"\"\\n\\n    def return_stopped_response(\\n        self,\\n        early_stopping_method: str,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        **kwargs: Any,\\n    ) -> AgentFinish:\\n        \"\"\"Return response when agent has been stopped due to max iterations.\"\"\"\\n        if early_stopping_method == \"force\":\\n            # `force` just returns a constant string\\n            return AgentFinish(\\n                {\"output\": \"Agent stopped due to iteration limit or time limit.\"}, \"\"\\n            )\\n        else:\\n            raise ValueError(\\n                f\"Got unsupported early_stopping_method `{early_stopping_method}`\"\\n            )\\n\\n    @classmethod\\n    def from_llm_and_tools(\\n        cls,\\n        llm: BaseLanguageModel,\\n        tools: Sequence[BaseTool],\\n        callback_manager: Optional[BaseCallbackManager] = None,\\n        **kwargs: Any,\\n    ) -> BaseSingleActionAgent:\\n        raise NotImplementedError\\n\\n    @property\\n    def _agent_type(self) -> str:\\n        \"\"\"Return Identifier of agent type.\"\"\"\\n        raise NotImplementedError\\n\\n    def dict(self, **kwargs: Any) -> Dict:\\n        \"\"\"Return dictionary representation of agent.\"\"\"\\n        _dict = super().dict()\\n        try:\\n            _type = self._agent_type\\n        except NotImplementedError:\\n            _type = None\\n        if isinstance(_type, AgentType):\\n            _dict[\"_type\"] = str(_type.value)\\n        elif _type is not None:\\n            _dict[\"_type\"] = _type\\n        return _dict\\n\\n    def save(self, file_path: Union[Path, str]) -> None:\\n        \"\"\"Save the agent.\\n\\n        Args:\\n            file_path: Path to file to save the agent to.\\n\\n        Example:\\n        .. code-block:: python\\n\\n            # If working with agent executor\\n            agent.agent.save(file_path=\"path/agent.yaml\")\\n        \"\"\"\\n        # Convert file to Path object.\\n        if isinstance(file_path, str):\\n            save_path = Path(file_path)\\n        else:\\n            save_path = file_path\\n\\n        directory_path = save_path.parent\\n        directory_path.mkdir(parents=True, exist_ok=True)\\n\\n        # Fetch dictionary to save\\n        agent_dict = self.dict()\\n        if \"_type\" not in agent_dict:\\n            raise NotImplementedError(f\"Agent {self} does not support saving\")\\n\\n        if save_path.suffix == \".json\":\\n            with open(file_path, \"w\") as f:\\n                json.dump(agent_dict, f, indent=4)\\n        elif save_path.suffix == \".yaml\":\\n            with open(file_path, \"w\") as f:\\n                yaml.dump(agent_dict, f, default_flow_style=False)\\n        else:\\n            raise ValueError(f\"{save_path} must be json or yaml\")\\n\\n    def tool_run_logging_kwargs(self) -> Dict:\\n        return {}',\n",
       "  'pos': 1758},\n",
       " 'RunnableMultiActionAgent': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class RunnableMultiActionAgent(BaseMultiActionAgent):\\n    \"\"\"Agent powered by runnables.\"\"\"\\n\\n    runnable: Runnable[dict, Union[List[AgentAction], AgentFinish]]\\n    \"\"\"Runnable to call to get agent actions.\"\"\"\\n    input_keys_arg: List[str] = []\\n    return_keys_arg: List[str] = []\\n\\n    class Config:\\n        \"\"\"Configuration for this pydantic object.\"\"\"\\n\\n        arbitrary_types_allowed = True\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        \"\"\"Return values of the agent.\"\"\"\\n        return self.return_keys_arg\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        Returns:\\n            List of input keys.\\n        \"\"\"\\n        return self.input_keys_arg\\n\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[\\n        List[AgentAction],\\n        AgentFinish,\\n    ]:\\n        \"\"\"Based on past history and current inputs, decide what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        inputs = {**kwargs, **{\"intermediate_steps\": intermediate_steps}}\\n        # Use streaming to make sure that the underlying LLM is invoked in a streaming\\n        # fashion to make it possible to get access to the individual LLM tokens\\n        # when using stream_log with the Agent Executor.\\n        # Because the response from the plan is not a generator, we need to\\n        # accumulate the output into final output and return that.\\n        final_output: Any = None\\n        for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}):\\n            if final_output is None:\\n                final_output = chunk\\n            else:\\n                final_output += chunk\\n\\n        return final_output\\n\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[\\n        List[AgentAction],\\n        AgentFinish,\\n    ]:\\n        \"\"\"Based on past history and current inputs, decide what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        inputs = {**kwargs, **{\"intermediate_steps\": intermediate_steps}}\\n        # Use streaming to make sure that the underlying LLM is invoked in a streaming\\n        # fashion to make it possible to get access to the individual LLM tokens\\n        # when using stream_log with the Agent Executor.\\n        # Because the response from the plan is not a generator, we need to\\n        # accumulate the output into final output and return that.\\n        final_output: Any = None\\n        async for chunk in self.runnable.astream(\\n            inputs, config={\"callbacks\": callbacks}\\n        ):\\n            if final_output is None:\\n                final_output = chunk\\n            else:\\n                final_output += chunk\\n\\n        return final_output',\n",
       "  'pos': 13433},\n",
       " 'MultiActionAgentOutputParser': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class MultiActionAgentOutputParser(\\n    BaseOutputParser[Union[List[AgentAction], AgentFinish]]\\n):\\n    \"\"\"Base class for parsing agent output into agent actions/finish.\"\"\"\\n\\n    @abstractmethod\\n    def parse(self, text: str) -> Union[List[AgentAction], AgentFinish]:\\n        \"\"\"Parse text into agent actions/finish.\"\"\"',\n",
       "  'pos': 9940},\n",
       " 'AgentExecutor': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class AgentExecutor(Chain):\\n    \"\"\"Agent that is using tools.\"\"\"\\n\\n    agent: Union[BaseSingleActionAgent, BaseMultiActionAgent]\\n    \"\"\"The agent to run for creating a plan and determining actions\\n    to take at each step of the execution loop.\"\"\"\\n    tools: Sequence[BaseTool]\\n    \"\"\"The valid tools the agent can call.\"\"\"\\n    return_intermediate_steps: bool = False\\n    \"\"\"Whether to return the agent\\'s trajectory of intermediate steps\\n    at the end in addition to the final output.\"\"\"\\n    max_iterations: Optional[int] = 15\\n    \"\"\"The maximum number of steps to take before ending the execution\\n    loop.\\n    \\n    Setting to \\'None\\' could lead to an infinite loop.\"\"\"\\n    max_execution_time: Optional[float] = None\\n    \"\"\"The maximum amount of wall clock time to spend in the execution\\n    loop.\\n    \"\"\"\\n    early_stopping_method: str = \"force\"\\n    \"\"\"The method to use for early stopping if the agent never\\n    returns `AgentFinish`. Either \\'force\\' or \\'generate\\'.\\n\\n    `\"force\"` returns a string saying that it stopped because it met a\\n        time or iteration limit.\\n    \\n    `\"generate\"` calls the agent\\'s LLM Chain one final time to generate\\n        a final answer based on the previous steps.\\n    \"\"\"\\n    handle_parsing_errors: Union[\\n        bool, str, Callable[[OutputParserException], str]\\n    ] = False\\n    \"\"\"How to handle errors raised by the agent\\'s output parser.\\n    Defaults to `False`, which raises the error.\\n    If `true`, the error will be sent back to the LLM as an observation.\\n    If a string, the string itself will be sent to the LLM as an observation.\\n    If a callable function, the function will be called with the exception\\n     as an argument, and the result of that function will be passed to the agent\\n      as an observation.\\n    \"\"\"\\n    trim_intermediate_steps: Union[\\n        int, Callable[[List[Tuple[AgentAction, str]]], List[Tuple[AgentAction, str]]]\\n    ] = -1\\n\\n    @classmethod\\n    def from_agent_and_tools(\\n        cls,\\n        agent: Union[BaseSingleActionAgent, BaseMultiActionAgent],\\n        tools: Sequence[BaseTool],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> AgentExecutor:\\n        \"\"\"Create from agent and tools.\"\"\"\\n        return cls(\\n            agent=agent,\\n            tools=tools,\\n            callbacks=callbacks,\\n            **kwargs,\\n        )\\n\\n    @root_validator()\\n    def validate_tools(cls, values: Dict) -> Dict:\\n        \"\"\"Validate that tools are compatible with agent.\"\"\"\\n        agent = values[\"agent\"]\\n        tools = values[\"tools\"]\\n        allowed_tools = agent.get_allowed_tools()\\n        if allowed_tools is not None:\\n            if set(allowed_tools) != set([tool.name for tool in tools]):\\n                raise ValueError(\\n                    f\"Allowed tools ({allowed_tools}) different than \"\\n                    f\"provided tools ({[tool.name for tool in tools]})\"\\n                )\\n        return values\\n\\n    @root_validator()\\n    def validate_return_direct_tool(cls, values: Dict) -> Dict:\\n        \"\"\"Validate that tools are compatible with agent.\"\"\"\\n        agent = values[\"agent\"]\\n        tools = values[\"tools\"]\\n        if isinstance(agent, BaseMultiActionAgent):\\n            for tool in tools:\\n                if tool.return_direct:\\n                    raise ValueError(\\n                        \"Tools that have `return_direct=True` are not allowed \"\\n                        \"in multi-action agents\"\\n                    )\\n        return values\\n\\n    @root_validator(pre=True)\\n    def validate_runnable_agent(cls, values: Dict) -> Dict:\\n        \"\"\"Convert runnable to agent if passed in.\"\"\"\\n        agent = values[\"agent\"]\\n        if isinstance(agent, Runnable):\\n            try:\\n                output_type = agent.OutputType\\n            except Exception as _:\\n                multi_action = False\\n            else:\\n                multi_action = output_type == Union[List[AgentAction], AgentFinish]\\n\\n            if multi_action:\\n                values[\"agent\"] = RunnableMultiActionAgent(runnable=agent)\\n            else:\\n                values[\"agent\"] = RunnableAgent(runnable=agent)\\n        return values\\n\\n    def save(self, file_path: Union[Path, str]) -> None:\\n        \"\"\"Raise error - saving not supported for Agent Executors.\"\"\"\\n        raise ValueError(\\n            \"Saving not supported for agent executors. \"\\n            \"If you are trying to save the agent, please use the \"\\n            \"`.save_agent(...)`\"\\n        )\\n\\n    def save_agent(self, file_path: Union[Path, str]) -> None:\\n        \"\"\"Save the underlying agent.\"\"\"\\n        return self.agent.save(file_path)\\n\\n    def iter(\\n        self,\\n        inputs: Any,\\n        callbacks: Callbacks = None,\\n        *,\\n        include_run_info: bool = False,\\n        async_: bool = False,  # arg kept for backwards compat, but ignored\\n    ) -> AgentExecutorIterator:\\n        \"\"\"Enables iteration over steps taken to reach final output.\"\"\"\\n        return AgentExecutorIterator(\\n            self,\\n            inputs,\\n            callbacks,\\n            tags=self.tags,\\n            include_run_info=include_run_info,\\n        )\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        :meta private:\\n        \"\"\"\\n        return self.agent.input_keys\\n\\n    @property\\n    def output_keys(self) -> List[str]:\\n        \"\"\"Return the singular output key.\\n\\n        :meta private:\\n        \"\"\"\\n        if self.return_intermediate_steps:\\n            return self.agent.return_values + [\"intermediate_steps\"]\\n        else:\\n            return self.agent.return_values\\n\\n    def lookup_tool(self, name: str) -> BaseTool:\\n        \"\"\"Lookup tool by name.\"\"\"\\n        return {tool.name: tool for tool in self.tools}[name]\\n\\n    def _should_continue(self, iterations: int, time_elapsed: float) -> bool:\\n        if self.max_iterations is not None and iterations >= self.max_iterations:\\n            return False\\n        if (\\n            self.max_execution_time is not None\\n            and time_elapsed >= self.max_execution_time\\n        ):\\n            return False\\n\\n        return True\\n\\n    def _return(\\n        self,\\n        output: AgentFinish,\\n        intermediate_steps: list,\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> Dict[str, Any]:\\n        if run_manager:\\n            run_manager.on_agent_finish(output, color=\"green\", verbose=self.verbose)\\n        final_output = output.return_values\\n        if self.return_intermediate_steps:\\n            final_output[\"intermediate_steps\"] = intermediate_steps\\n        return final_output\\n\\n    async def _areturn(\\n        self,\\n        output: AgentFinish,\\n        intermediate_steps: list,\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> Dict[str, Any]:\\n        if run_manager:\\n            await run_manager.on_agent_finish(\\n                output, color=\"green\", verbose=self.verbose\\n            )\\n        final_output = output.return_values\\n        if self.return_intermediate_steps:\\n            final_output[\"intermediate_steps\"] = intermediate_steps\\n        return final_output\\n\\n    def _consume_next_step(\\n        self, values: NextStepOutput\\n    ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\\n        if isinstance(values[-1], AgentFinish):\\n            assert len(values) == 1\\n            return values[-1]\\n        else:\\n            return [\\n                (a.action, a.observation) for a in values if isinstance(a, AgentStep)\\n            ]\\n\\n    def _take_next_step(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        inputs: Dict[str, str],\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\\n        return self._consume_next_step(\\n            [\\n                a\\n                for a in self._iter_next_step(\\n                    name_to_tool_map,\\n                    color_mapping,\\n                    inputs,\\n                    intermediate_steps,\\n                    run_manager,\\n                )\\n            ]\\n        )\\n\\n    def _iter_next_step(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        inputs: Dict[str, str],\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> Iterator[Union[AgentFinish, AgentAction, AgentStep]]:\\n        \"\"\"Take a single step in the thought-action-observation loop.\\n\\n        Override this to take control of how the agent makes and acts on choices.\\n        \"\"\"\\n        try:\\n            intermediate_steps = self._prepare_intermediate_steps(intermediate_steps)\\n\\n            # Call the LLM to see what to do.\\n            output = self.agent.plan(\\n                intermediate_steps,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **inputs,\\n            )\\n        except OutputParserException as e:\\n            if isinstance(self.handle_parsing_errors, bool):\\n                raise_error = not self.handle_parsing_errors\\n            else:\\n                raise_error = False\\n            if raise_error:\\n                raise ValueError(\\n                    \"An output parsing error occurred. \"\\n                    \"In order to pass this error back to the agent and have it try \"\\n                    \"again, pass `handle_parsing_errors=True` to the AgentExecutor. \"\\n                    f\"This is the error: {str(e)}\"\\n                )\\n            text = str(e)\\n            if isinstance(self.handle_parsing_errors, bool):\\n                if e.send_to_llm:\\n                    observation = str(e.observation)\\n                    text = str(e.llm_output)\\n                else:\\n                    observation = \"Invalid or incomplete response\"\\n            elif isinstance(self.handle_parsing_errors, str):\\n                observation = self.handle_parsing_errors\\n            elif callable(self.handle_parsing_errors):\\n                observation = self.handle_parsing_errors(e)\\n            else:\\n                raise ValueError(\"Got unexpected type of `handle_parsing_errors`\")\\n            output = AgentAction(\"_Exception\", observation, text)\\n            if run_manager:\\n                run_manager.on_agent_action(output, color=\"green\")\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            observation = ExceptionTool().run(\\n                output.tool_input,\\n                verbose=self.verbose,\\n                color=None,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n            yield AgentStep(action=output, observation=observation)\\n            return\\n\\n        # If the tool chosen is the finishing tool, then we end and return.\\n        if isinstance(output, AgentFinish):\\n            yield output\\n            return\\n\\n        actions: List[AgentAction]\\n        if isinstance(output, AgentAction):\\n            actions = [output]\\n        else:\\n            actions = output\\n        for agent_action in actions:\\n            yield agent_action\\n        for agent_action in actions:\\n            yield self._perform_agent_action(\\n                name_to_tool_map, color_mapping, agent_action, run_manager\\n            )\\n\\n    def _perform_agent_action(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        agent_action: AgentAction,\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> AgentStep:\\n        if run_manager:\\n            run_manager.on_agent_action(agent_action, color=\"green\")\\n        # Otherwise we lookup the tool\\n        if agent_action.tool in name_to_tool_map:\\n            tool = name_to_tool_map[agent_action.tool]\\n            return_direct = tool.return_direct\\n            color = color_mapping[agent_action.tool]\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            if return_direct:\\n                tool_run_kwargs[\"llm_prefix\"] = \"\"\\n            # We then call the tool on the tool input to get an observation\\n            observation = tool.run(\\n                agent_action.tool_input,\\n                verbose=self.verbose,\\n                color=color,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n        else:\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            observation = InvalidTool().run(\\n                {\\n                    \"requested_tool_name\": agent_action.tool,\\n                    \"available_tool_names\": list(name_to_tool_map.keys()),\\n                },\\n                verbose=self.verbose,\\n                color=None,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n        return AgentStep(action=agent_action, observation=observation)\\n\\n    async def _atake_next_step(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        inputs: Dict[str, str],\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\\n        return self._consume_next_step(\\n            [\\n                a\\n                async for a in self._aiter_next_step(\\n                    name_to_tool_map,\\n                    color_mapping,\\n                    inputs,\\n                    intermediate_steps,\\n                    run_manager,\\n                )\\n            ]\\n        )\\n\\n    async def _aiter_next_step(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        inputs: Dict[str, str],\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> AsyncIterator[Union[AgentFinish, AgentAction, AgentStep]]:\\n        \"\"\"Take a single step in the thought-action-observation loop.\\n\\n        Override this to take control of how the agent makes and acts on choices.\\n        \"\"\"\\n        try:\\n            intermediate_steps = self._prepare_intermediate_steps(intermediate_steps)\\n\\n            # Call the LLM to see what to do.\\n            output = await self.agent.aplan(\\n                intermediate_steps,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **inputs,\\n            )\\n        except OutputParserException as e:\\n            if isinstance(self.handle_parsing_errors, bool):\\n                raise_error = not self.handle_parsing_errors\\n            else:\\n                raise_error = False\\n            if raise_error:\\n                raise ValueError(\\n                    \"An output parsing error occurred. \"\\n                    \"In order to pass this error back to the agent and have it try \"\\n                    \"again, pass `handle_parsing_errors=True` to the AgentExecutor. \"\\n                    f\"This is the error: {str(e)}\"\\n                )\\n            text = str(e)\\n            if isinstance(self.handle_parsing_errors, bool):\\n                if e.send_to_llm:\\n                    observation = str(e.observation)\\n                    text = str(e.llm_output)\\n                else:\\n                    observation = \"Invalid or incomplete response\"\\n            elif isinstance(self.handle_parsing_errors, str):\\n                observation = self.handle_parsing_errors\\n            elif callable(self.handle_parsing_errors):\\n                observation = self.handle_parsing_errors(e)\\n            else:\\n                raise ValueError(\"Got unexpected type of `handle_parsing_errors`\")\\n            output = AgentAction(\"_Exception\", observation, text)\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            observation = await ExceptionTool().arun(\\n                output.tool_input,\\n                verbose=self.verbose,\\n                color=None,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n            yield AgentStep(action=output, observation=observation)\\n            return\\n\\n        # If the tool chosen is the finishing tool, then we end and return.\\n        if isinstance(output, AgentFinish):\\n            yield output\\n            return\\n\\n        actions: List[AgentAction]\\n        if isinstance(output, AgentAction):\\n            actions = [output]\\n        else:\\n            actions = output\\n        for agent_action in actions:\\n            yield agent_action\\n\\n        # Use asyncio.gather to run multiple tool.arun() calls concurrently\\n        result = await asyncio.gather(\\n            *[\\n                self._aperform_agent_action(\\n                    name_to_tool_map, color_mapping, agent_action, run_manager\\n                )\\n                for agent_action in actions\\n            ],\\n        )\\n\\n        # TODO This could yield each result as it becomes available\\n        for chunk in result:\\n            yield chunk\\n\\n    async def _aperform_agent_action(\\n        self,\\n        name_to_tool_map: Dict[str, BaseTool],\\n        color_mapping: Dict[str, str],\\n        agent_action: AgentAction,\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> AgentStep:\\n        if run_manager:\\n            await run_manager.on_agent_action(\\n                agent_action, verbose=self.verbose, color=\"green\"\\n            )\\n        # Otherwise we lookup the tool\\n        if agent_action.tool in name_to_tool_map:\\n            tool = name_to_tool_map[agent_action.tool]\\n            return_direct = tool.return_direct\\n            color = color_mapping[agent_action.tool]\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            if return_direct:\\n                tool_run_kwargs[\"llm_prefix\"] = \"\"\\n            # We then call the tool on the tool input to get an observation\\n            observation = await tool.arun(\\n                agent_action.tool_input,\\n                verbose=self.verbose,\\n                color=color,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n        else:\\n            tool_run_kwargs = self.agent.tool_run_logging_kwargs()\\n            observation = await InvalidTool().arun(\\n                {\\n                    \"requested_tool_name\": agent_action.tool,\\n                    \"available_tool_names\": list(name_to_tool_map.keys()),\\n                },\\n                verbose=self.verbose,\\n                color=None,\\n                callbacks=run_manager.get_child() if run_manager else None,\\n                **tool_run_kwargs,\\n            )\\n        return AgentStep(action=agent_action, observation=observation)\\n\\n    def _call(\\n        self,\\n        inputs: Dict[str, str],\\n        run_manager: Optional[CallbackManagerForChainRun] = None,\\n    ) -> Dict[str, Any]:\\n        \"\"\"Run text through and get agent response.\"\"\"\\n        # Construct a mapping of tool name to tool for easy lookup\\n        name_to_tool_map = {tool.name: tool for tool in self.tools}\\n        # We construct a mapping from each tool to a color, used for logging.\\n        color_mapping = get_color_mapping(\\n            [tool.name for tool in self.tools], excluded_colors=[\"green\", \"red\"]\\n        )\\n        intermediate_steps: List[Tuple[AgentAction, str]] = []\\n        # Let\\'s start tracking the number of iterations and time elapsed\\n        iterations = 0\\n        time_elapsed = 0.0\\n        start_time = time.time()\\n        # We now enter the agent loop (until it returns something).\\n        while self._should_continue(iterations, time_elapsed):\\n            next_step_output = self._take_next_step(\\n                name_to_tool_map,\\n                color_mapping,\\n                inputs,\\n                intermediate_steps,\\n                run_manager=run_manager,\\n            )\\n            if isinstance(next_step_output, AgentFinish):\\n                return self._return(\\n                    next_step_output, intermediate_steps, run_manager=run_manager\\n                )\\n\\n            intermediate_steps.extend(next_step_output)\\n            if len(next_step_output) == 1:\\n                next_step_action = next_step_output[0]\\n                # See if tool should return directly\\n                tool_return = self._get_tool_return(next_step_action)\\n                if tool_return is not None:\\n                    return self._return(\\n                        tool_return, intermediate_steps, run_manager=run_manager\\n                    )\\n            iterations += 1\\n            time_elapsed = time.time() - start_time\\n        output = self.agent.return_stopped_response(\\n            self.early_stopping_method, intermediate_steps, **inputs\\n        )\\n        return self._return(output, intermediate_steps, run_manager=run_manager)\\n\\n    async def _acall(\\n        self,\\n        inputs: Dict[str, str],\\n        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\\n    ) -> Dict[str, str]:\\n        \"\"\"Run text through and get agent response.\"\"\"\\n        # Construct a mapping of tool name to tool for easy lookup\\n        name_to_tool_map = {tool.name: tool for tool in self.tools}\\n        # We construct a mapping from each tool to a color, used for logging.\\n        color_mapping = get_color_mapping(\\n            [tool.name for tool in self.tools], excluded_colors=[\"green\"]\\n        )\\n        intermediate_steps: List[Tuple[AgentAction, str]] = []\\n        # Let\\'s start tracking the number of iterations and time elapsed\\n        iterations = 0\\n        time_elapsed = 0.0\\n        start_time = time.time()\\n        # We now enter the agent loop (until it returns something).\\n        try:\\n            async with asyncio_timeout(self.max_execution_time):\\n                while self._should_continue(iterations, time_elapsed):\\n                    next_step_output = await self._atake_next_step(\\n                        name_to_tool_map,\\n                        color_mapping,\\n                        inputs,\\n                        intermediate_steps,\\n                        run_manager=run_manager,\\n                    )\\n                    if isinstance(next_step_output, AgentFinish):\\n                        return await self._areturn(\\n                            next_step_output,\\n                            intermediate_steps,\\n                            run_manager=run_manager,\\n                        )\\n\\n                    intermediate_steps.extend(next_step_output)\\n                    if len(next_step_output) == 1:\\n                        next_step_action = next_step_output[0]\\n                        # See if tool should return directly\\n                        tool_return = self._get_tool_return(next_step_action)\\n                        if tool_return is not None:\\n                            return await self._areturn(\\n                                tool_return, intermediate_steps, run_manager=run_manager\\n                            )\\n\\n                    iterations += 1\\n                    time_elapsed = time.time() - start_time\\n                output = self.agent.return_stopped_response(\\n                    self.early_stopping_method, intermediate_steps, **inputs\\n                )\\n                return await self._areturn(\\n                    output, intermediate_steps, run_manager=run_manager\\n                )\\n        except (TimeoutError, asyncio.TimeoutError):\\n            # stop early when interrupted by the async timeout\\n            output = self.agent.return_stopped_response(\\n                self.early_stopping_method, intermediate_steps, **inputs\\n            )\\n            return await self._areturn(\\n                output, intermediate_steps, run_manager=run_manager\\n            )\\n\\n    def _get_tool_return(\\n        self, next_step_output: Tuple[AgentAction, str]\\n    ) -> Optional[AgentFinish]:\\n        \"\"\"Check if the tool is a returning tool.\"\"\"\\n        agent_action, observation = next_step_output\\n        name_to_tool_map = {tool.name: tool for tool in self.tools}\\n        return_value_key = \"output\"\\n        if len(self.agent.return_values) > 0:\\n            return_value_key = self.agent.return_values[0]\\n        # Invalid tools won\\'t be in the map, so we return False.\\n        if agent_action.tool in name_to_tool_map:\\n            if name_to_tool_map[agent_action.tool].return_direct:\\n                return AgentFinish(\\n                    {return_value_key: observation},\\n                    \"\",\\n                )\\n        return None\\n\\n    def _prepare_intermediate_steps(\\n        self, intermediate_steps: List[Tuple[AgentAction, str]]\\n    ) -> List[Tuple[AgentAction, str]]:\\n        if (\\n            isinstance(self.trim_intermediate_steps, int)\\n            and self.trim_intermediate_steps > 0\\n        ):\\n            return intermediate_steps[-self.trim_intermediate_steps :]\\n        elif callable(self.trim_intermediate_steps):\\n            return self.trim_intermediate_steps(intermediate_steps)\\n        else:\\n            return intermediate_steps\\n\\n    def stream(\\n        self,\\n        input: Union[Dict[str, Any], Any],\\n        config: Optional[RunnableConfig] = None,\\n        **kwargs: Any,\\n    ) -> Iterator[AddableDict]:\\n        \"\"\"Enables streaming over steps taken to reach final output.\"\"\"\\n        config = ensure_config(config)\\n        iterator = AgentExecutorIterator(\\n            self,\\n            input,\\n            config.get(\"callbacks\"),\\n            tags=config.get(\"tags\"),\\n            metadata=config.get(\"metadata\"),\\n            run_name=config.get(\"run_name\"),\\n            yield_actions=True,\\n            **kwargs,\\n        )\\n        for step in iterator:\\n            yield step\\n\\n    async def astream(\\n        self,\\n        input: Union[Dict[str, Any], Any],\\n        config: Optional[RunnableConfig] = None,\\n        **kwargs: Any,\\n    ) -> AsyncIterator[AddableDict]:\\n        \"\"\"Enables streaming over steps taken to reach final output.\"\"\"\\n        config = ensure_config(config)\\n        iterator = AgentExecutorIterator(\\n            self,\\n            input,\\n            config.get(\"callbacks\"),\\n            tags=config.get(\"tags\"),\\n            metadata=config.get(\"metadata\"),\\n            run_name=config.get(\"run_name\"),\\n            yield_actions=True,\\n            **kwargs,\\n        )\\n        async for step in iterator:\\n            yield step',\n",
       "  'pos': 28269},\n",
       " 'Agent': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class Agent(BaseSingleActionAgent):\\n    \"\"\"Agent that calls the language model and deciding the action.\\n\\n    This is driven by an LLMChain. The prompt in the LLMChain MUST include\\n    a variable called \"agent_scratchpad\" where the agent can put its\\n    intermediary work.\\n    \"\"\"\\n\\n    llm_chain: LLMChain\\n    output_parser: AgentOutputParser\\n    allowed_tools: Optional[List[str]] = None\\n\\n    def dict(self, **kwargs: Any) -> Dict:\\n        \"\"\"Return dictionary representation of agent.\"\"\"\\n        _dict = super().dict()\\n        del _dict[\"output_parser\"]\\n        return _dict\\n\\n    def get_allowed_tools(self) -> Optional[List[str]]:\\n        return self.allowed_tools\\n\\n    @property\\n    def return_values(self) -> List[str]:\\n        return [\"output\"]\\n\\n    def _fix_text(self, text: str) -> str:\\n        \"\"\"Fix the text.\"\"\"\\n        raise ValueError(\"fix_text not implemented for this agent.\")\\n\\n    @property\\n    def _stop(self) -> List[str]:\\n        return [\\n            f\"\\\\n{self.observation_prefix.rstrip()}\",\\n            f\"\\\\n\\\\t{self.observation_prefix.rstrip()}\",\\n        ]\\n\\n    def _construct_scratchpad(\\n        self, intermediate_steps: List[Tuple[AgentAction, str]]\\n    ) -> Union[str, List[BaseMessage]]:\\n        \"\"\"Construct the scratchpad that lets the agent continue its thought process.\"\"\"\\n        thoughts = \"\"\\n        for action, observation in intermediate_steps:\\n            thoughts += action.log\\n            thoughts += f\"\\\\n{self.observation_prefix}{observation}\\\\n{self.llm_prefix}\"\\n        return thoughts\\n\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        full_inputs = self.get_full_inputs(intermediate_steps, **kwargs)\\n        full_output = self.llm_chain.predict(callbacks=callbacks, **full_inputs)\\n        return self.output_parser.parse(full_output)\\n\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        full_inputs = self.get_full_inputs(intermediate_steps, **kwargs)\\n        full_output = await self.llm_chain.apredict(callbacks=callbacks, **full_inputs)\\n        agent_output = await self.output_parser.aparse(full_output)\\n        return agent_output\\n\\n    def get_full_inputs(\\n        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\\n    ) -> Dict[str, Any]:\\n        \"\"\"Create the full inputs for the LLMChain from intermediate steps.\"\"\"\\n        thoughts = self._construct_scratchpad(intermediate_steps)\\n        new_inputs = {\"agent_scratchpad\": thoughts, \"stop\": self._stop}\\n        full_inputs = {**kwargs, **new_inputs}\\n        return full_inputs\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        :meta private:\\n        \"\"\"\\n        return list(set(self.llm_chain.input_keys) - {\"agent_scratchpad\"})\\n\\n    @root_validator()\\n    def validate_prompt(cls, values: Dict) -> Dict:\\n        \"\"\"Validate that prompt matches format.\"\"\"\\n        prompt = values[\"llm_chain\"].prompt\\n        if \"agent_scratchpad\" not in prompt.input_variables:\\n            logger.warning(\\n                \"`agent_scratchpad` should be a variable in prompt.input_variables.\"\\n                \" Did not find it, so adding it at the end.\"\\n            )\\n            prompt.input_variables.append(\"agent_scratchpad\")\\n            if isinstance(prompt, PromptTemplate):\\n                prompt.template += \"\\\\n{agent_scratchpad}\"\\n            elif isinstance(prompt, FewShotPromptTemplate):\\n                prompt.suffix += \"\\\\n{agent_scratchpad}\"\\n            else:\\n                raise ValueError(f\"Got unexpected prompt type {type(prompt)}\")\\n        return values\\n\\n    @property\\n    @abstractmethod\\n    def observation_prefix(self) -> str:\\n        \"\"\"Prefix to append the observation with.\"\"\"\\n\\n    @property\\n    @abstractmethod\\n    def llm_prefix(self) -> str:\\n        \"\"\"Prefix to append the LLM call with.\"\"\"\\n\\n    @classmethod\\n    @abstractmethod\\n    def create_prompt(cls, tools: Sequence[BaseTool]) -> BasePromptTemplate:\\n        \"\"\"Create a prompt for this class.\"\"\"\\n\\n    @classmethod\\n    def _validate_tools(cls, tools: Sequence[BaseTool]) -> None:\\n        \"\"\"Validate that appropriate tools are passed in.\"\"\"\\n        pass\\n\\n    @classmethod\\n    @abstractmethod\\n    def _get_default_output_parser(cls, **kwargs: Any) -> AgentOutputParser:\\n        \"\"\"Get default output parser for this class.\"\"\"\\n\\n    @classmethod\\n    def from_llm_and_tools(\\n        cls,\\n        llm: BaseLanguageModel,\\n        tools: Sequence[BaseTool],\\n        callback_manager: Optional[BaseCallbackManager] = None,\\n        output_parser: Optional[AgentOutputParser] = None,\\n        **kwargs: Any,\\n    ) -> Agent:\\n        \"\"\"Construct an agent from an LLM and tools.\"\"\"\\n        cls._validate_tools(tools)\\n        llm_chain = LLMChain(\\n            llm=llm,\\n            prompt=cls.create_prompt(tools),\\n            callback_manager=callback_manager,\\n        )\\n        tool_names = [tool.name for tool in tools]\\n        _output_parser = output_parser or cls._get_default_output_parser()\\n        return cls(\\n            llm_chain=llm_chain,\\n            allowed_tools=tool_names,\\n            output_parser=_output_parser,\\n            **kwargs,\\n        )\\n\\n    def return_stopped_response(\\n        self,\\n        early_stopping_method: str,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        **kwargs: Any,\\n    ) -> AgentFinish:\\n        \"\"\"Return response when agent has been stopped due to max iterations.\"\"\"\\n        if early_stopping_method == \"force\":\\n            # `force` just returns a constant string\\n            return AgentFinish(\\n                {\"output\": \"Agent stopped due to iteration limit or time limit.\"}, \"\"\\n            )\\n        elif early_stopping_method == \"generate\":\\n            # Generate does one final forward pass\\n            thoughts = \"\"\\n            for action, observation in intermediate_steps:\\n                thoughts += action.log\\n                thoughts += (\\n                    f\"\\\\n{self.observation_prefix}{observation}\\\\n{self.llm_prefix}\"\\n                )\\n            # Adding to the previous steps, we now tell the LLM to make a final pred\\n            thoughts += (\\n                \"\\\\n\\\\nI now need to return a final answer based on the previous steps:\"\\n            )\\n            new_inputs = {\"agent_scratchpad\": thoughts, \"stop\": self._stop}\\n            full_inputs = {**kwargs, **new_inputs}\\n            full_output = self.llm_chain.predict(**full_inputs)\\n            # We try to extract a final answer\\n            parsed_output = self.output_parser.parse(full_output)\\n            if isinstance(parsed_output, AgentFinish):\\n                # If we can extract, we send the correct stuff\\n                return parsed_output\\n            else:\\n                # If we can extract, but the tool is not the final tool,\\n                # we just return the full output\\n                return AgentFinish({\"output\": full_output}, full_output)\\n        else:\\n            raise ValueError(\\n                \"early_stopping_method should be one of `force` or `generate`, \"\\n                f\"got {early_stopping_method}\"\\n            )\\n\\n    def tool_run_logging_kwargs(self) -> Dict:\\n        return {\\n            \"llm_prefix\": self.llm_prefix,\\n            \"observation_prefix\": self.observation_prefix,\\n        }',\n",
       "  'pos': 19563},\n",
       " 'LLMSingleActionAgent': {'type': 'mannual_defined_class',\n",
       "  'code_body': 'class LLMSingleActionAgent(BaseSingleActionAgent):\\n    \"\"\"Base class for single action agents.\"\"\"\\n\\n    llm_chain: LLMChain\\n    \"\"\"LLMChain to use for agent.\"\"\"\\n    output_parser: AgentOutputParser\\n    \"\"\"Output parser to use for agent.\"\"\"\\n    stop: List[str]\\n    \"\"\"List of strings to stop on.\"\"\"\\n\\n    @property\\n    def input_keys(self) -> List[str]:\\n        \"\"\"Return the input keys.\\n\\n        Returns:\\n            List of input keys.\\n        \"\"\"\\n        return list(set(self.llm_chain.input_keys) - {\"intermediate_steps\"})\\n\\n    def dict(self, **kwargs: Any) -> Dict:\\n        \"\"\"Return dictionary representation of agent.\"\"\"\\n        _dict = super().dict()\\n        del _dict[\"output_parser\"]\\n        return _dict\\n\\n    def plan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with the observations.\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        output = self.llm_chain.run(\\n            intermediate_steps=intermediate_steps,\\n            stop=self.stop,\\n            callbacks=callbacks,\\n            **kwargs,\\n        )\\n        return self.output_parser.parse(output)\\n\\n    async def aplan(\\n        self,\\n        intermediate_steps: List[Tuple[AgentAction, str]],\\n        callbacks: Callbacks = None,\\n        **kwargs: Any,\\n    ) -> Union[AgentAction, AgentFinish]:\\n        \"\"\"Given input, decided what to do.\\n\\n        Args:\\n            intermediate_steps: Steps the LLM has taken to date,\\n                along with observations\\n            callbacks: Callbacks to run.\\n            **kwargs: User inputs.\\n\\n        Returns:\\n            Action specifying what tool to use.\\n        \"\"\"\\n        output = await self.llm_chain.arun(\\n            intermediate_steps=intermediate_steps,\\n            stop=self.stop,\\n            callbacks=callbacks,\\n            **kwargs,\\n        )\\n        return self.output_parser.parse(output)\\n\\n    def tool_run_logging_kwargs(self) -> Dict:\\n        return {\\n            \"llm_prefix\": \"\",\\n            \"observation_prefix\": \"\" if len(self.stop) == 0 else self.stop[0],\\n        }',\n",
       "  'pos': 16964}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['symbols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
